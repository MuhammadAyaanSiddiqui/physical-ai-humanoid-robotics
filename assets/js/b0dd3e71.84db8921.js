"use strict";(globalThis.webpackChunkphysical_ai_course=globalThis.webpackChunkphysical_ai_course||[]).push([[3941],{6964:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"module-4-vla/ch11-whisper/audio-capture","title":"Audio Capture with ReSpeaker Microphone","description":"Learning Objectives","source":"@site/docs/module-4-vla/ch11-whisper/audio-capture.md","sourceDirName":"module-4-vla/ch11-whisper","slug":"/module-4-vla/ch11-whisper/audio-capture","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch11-whisper/audio-capture","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/ch11-whisper/audio-capture.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 3 Assessment: Perception + Navigation Project","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/assessment"},"next":{"title":"Speech-to-Text with OpenAI Whisper API","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch11-whisper/whisper-api"}}');var s=i(4848),a=i(8453);const l={},o="Audio Capture with ReSpeaker Microphone",t={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Part 1: Hardware Setup",id:"part-1-hardware-setup",level:2},{value:"Step 1: Verify ReSpeaker USB Connection",id:"step-1-verify-respeaker-usb-connection",level:3},{value:"Step 2: Install ReSpeaker Python Library",id:"step-2-install-respeaker-python-library",level:3},{value:"Step 3: Test LED Ring Control",id:"step-3-test-led-ring-control",level:3},{value:"Part 2: Audio Recording with ALSA",id:"part-2-audio-recording-with-alsa",level:2},{value:"Step 1: Record Test Audio",id:"step-1-record-test-audio",level:3},{value:"Step 2: Python Audio Capture",id:"step-2-python-audio-capture",level:3},{value:"Part 3: Beamforming and Noise Cancellation",id:"part-3-beamforming-and-noise-cancellation",level:2},{value:"Step 1: Access DSP Parameters",id:"step-1-access-dsp-parameters",level:3},{value:"Step 2: Enable Beamforming",id:"step-2-enable-beamforming",level:3},{value:"Step 3: Real-Time DOA Visualization",id:"step-3-real-time-doa-visualization",level:3},{value:"Part 4: ROS 2 Integration",id:"part-4-ros-2-integration",level:2},{value:"Step 1: Create Audio Publisher Node",id:"step-1-create-audio-publisher-node",level:3},{value:"Step 2: Install audio_common_msgs",id:"step-2-install-audio_common_msgs",level:3},{value:"Step 3: Test Audio Stream",id:"step-3-test-audio-stream",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Exercise 1: Circular Buffer Recording",id:"exercise-1-circular-buffer-recording",level:3},{value:"Exercise 2: Voice Activity Detection (VAD)",id:"exercise-2-voice-activity-detection-vad",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Issue 1: &quot;ReSpeaker not found&quot; error",id:"issue-1-respeaker-not-found-error",level:3},{value:"Issue 2: &quot;Input overflowed&quot; warning",id:"issue-2-input-overflowed-warning",level:3},{value:"Issue 3: Poor audio quality with noise",id:"issue-3-poor-audio-quality-with-noise",level:3},{value:"Issue 4: LEDs not working",id:"issue-4-leds-not-working",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Latency Reduction",id:"latency-reduction",level:3},{value:"Multi-Microphone Processing",id:"multi-microphone-processing",level:3},{value:"Summary",id:"summary",level:2},{value:"Additional Resources",id:"additional-resources",level:2},{value:"Official Documentation",id:"official-documentation",level:3},{value:"Research Papers",id:"research-papers",level:3},{value:"Code Examples",id:"code-examples",level:3},{value:"Video Tutorials",id:"video-tutorials",level:3},{value:"Next Lesson",id:"next-lesson",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"audio-capture-with-respeaker-microphone",children:"Audio Capture with ReSpeaker Microphone"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Set up ReSpeaker USB microphone arrays for far-field audio capture"}),"\n",(0,s.jsx)(n.li,{children:"Configure ALSA (Advanced Linux Sound Architecture) for low-latency recording"}),"\n",(0,s.jsx)(n.li,{children:"Implement circular buffer audio streaming in Python"}),"\n",(0,s.jsx)(n.li,{children:"Apply beamforming and noise cancellation for robot environments"}),"\n",(0,s.jsx)(n.li,{children:"Integrate audio capture with ROS 2 for downstream speech processing"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Required Knowledge"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Basic Linux command-line operations"}),"\n",(0,s.jsx)(n.li,{children:"Python programming (file I/O, threading)"}),"\n",(0,s.jsx)(n.li,{children:"Understanding of audio concepts (sample rate, bit depth, channels)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Required Hardware"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"ReSpeaker Mic Array v2.0 (6-mic circular array) or 4-Mic Linear Array"}),"\n",(0,s.jsx)(n.li,{children:"Host computer running Ubuntu 22.04"}),"\n",(0,s.jsx)(n.li,{children:"USB 2.0 port (minimum)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Required Software"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ubuntu 22.04 (or compatible Linux distribution)"}),"\n",(0,s.jsx)(n.li,{children:"Python 3.10+"}),"\n",(0,s.jsx)(n.li,{children:"ROS 2 Humble (for integration exercises)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Estimated Time"}),": 2-3 hours"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"Voice-controlled humanoid robots require robust far-field audio capture to understand commands in noisy environments. Unlike smartphone microphones designed for near-field (10-30cm) speech, robotics applications demand:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Far-field capture"}),": 1-5 meters from the speaker"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Noise rejection"}),": Filtering motor noise, fans, ambient sounds"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Directionality"}),": Beamforming to focus on speaker location"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Low latency"}),": <100ms for real-time interaction"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Seeed Studio ReSpeaker"})," microphone arrays are purpose-built for these requirements, featuring:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"6 or 4 MEMS microphones in circular/linear configuration"}),"\n",(0,s.jsx)(n.li,{children:"Onboard XVSM-2000 DSP chip for beamforming"}),"\n",(0,s.jsx)(n.li,{children:"USB audio device interface (plug-and-play)"}),"\n",(0,s.jsx)(n.li,{children:"LED ring for visual feedback"}),"\n",(0,s.jsx)(n.li,{children:"Support for 16 kHz sample rate (optimal for speech)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"part-1-hardware-setup",children:"Part 1: Hardware Setup"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-verify-respeaker-usb-connection",children:"Step 1: Verify ReSpeaker USB Connection"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Connect ReSpeaker to a USB 2.0 port (USB 3.0 may cause compatibility issues)"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Verify the device is detected:"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'lsusb | grep "2886:0018"\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected output"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Bus 001 Device 005: ID 2886:0018 Seeed Technology Co., Ltd. ReSpeaker MicArray v2.0\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsx)(n.li,{children:"Check ALSA device listing:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"arecord -l\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected output"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"**** List of CAPTURE Hardware Devices ****\ncard 1: ArrayUAC10 [ReSpeaker 4 Mic Array (UAC1.0)], device 0: USB Audio [USB Audio]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Note the ",(0,s.jsx)(n.strong,{children:"card number"})," (e.g., ",(0,s.jsx)(n.code,{children:"card 1"}),") and ",(0,s.jsx)(n.strong,{children:"device number"})," (e.g., ",(0,s.jsx)(n.code,{children:"device 0"}),")."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-2-install-respeaker-python-library",children:"Step 2: Install ReSpeaker Python Library"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"respeaker"})," Python library provides access to the DSP chip for beamforming and LED control."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Install system dependencies\nsudo apt update\nsudo apt install -y python3-pyaudio portaudio19-dev libatlas-base-dev\n\n# Install Python libraries\npip3 install pyusb respeaker pixel-ring hid\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Verify installation"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 -c \"import usb.core; print('PyUSB OK')\"\npython3 -c \"import pixel_ring; print('pixel_ring OK')\"\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-3-test-led-ring-control",children:"Step 3: Test LED Ring Control"}),"\n",(0,s.jsx)(n.p,{children:"The ReSpeaker's LED ring provides visual feedback (e.g., indicating listening state)."}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.code,{children:"test_led.py"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport time\nfrom pixel_ring import pixel_ring\n\n# Initialize LED ring\npixel_ring.set_brightness(10)  # 0-100\n\n# Test pattern: spinning blue light\nprint("Testing LED ring (Ctrl+C to stop)...")\ntry:\n    while True:\n        for i in range(12):  # 12 LEDs on v2.0\n            pixel_ring.set_color_palette(i, 0x0000FF)  # Blue\n            time.sleep(0.1)\n            pixel_ring.set_color_palette(i, 0x000000)  # Off\nexcept KeyboardInterrupt:\n    pixel_ring.off()\n    print("\\nLED test complete")\n'})}),"\n",(0,s.jsx)(n.p,{children:"Run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"chmod +x test_led.py\npython3 test_led.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"You should see a blue light spinning around the ring."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"part-2-audio-recording-with-alsa",children:"Part 2: Audio Recording with ALSA"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-record-test-audio",children:"Step 1: Record Test Audio"}),"\n",(0,s.jsxs)(n.p,{children:["Use ALSA's ",(0,s.jsx)(n.code,{children:"arecord"})," to capture raw audio:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Record 5 seconds of audio from ReSpeaker\n# Replace hw:1,0 with your card:device from Step 1\narecord -D plughw:1,0 -f S16_LE -r 16000 -c 6 -d 5 test.wav\n\n# Play back the recording\naplay test.wav\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Parameters explained"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-D plughw:1,0"}),": Device (card 1, device 0)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-f S16_LE"}),": Format (16-bit signed little-endian)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-r 16000"}),": Sample rate (16 kHz - standard for speech)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-c 6"}),": Channels (6 microphones on v2.0, use ",(0,s.jsx)(n.code,{children:"-c 4"})," for 4-mic version)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-d 5"}),": Duration (5 seconds)"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-2-python-audio-capture",children:"Step 2: Python Audio Capture"}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.code,{children:"capture_audio.py"})," for programmatic recording:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport pyaudio\nimport wave\nimport numpy as np\n\n# Configuration\nRESPEAKER_RATE = 16000\nRESPEAKER_CHANNELS = 6  # Change to 4 for 4-mic array\nRESPEAKER_WIDTH = 2     # 2 bytes = 16-bit\nRESPEAKER_INDEX = 1     # From arecord -l (card number)\nCHUNK = 1024\nRECORD_SECONDS = 5\nWAVE_OUTPUT_FILENAME = "output.wav"\n\n# Initialize PyAudio\np = pyaudio.PyAudio()\n\n# Open stream\nstream = p.open(\n    rate=RESPEAKER_RATE,\n    format=p.get_format_from_width(RESPEAKER_WIDTH),\n    channels=RESPEAKER_CHANNELS,\n    input=True,\n    input_device_index=RESPEAKER_INDEX,\n    frames_per_buffer=CHUNK\n)\n\nprint(f"Recording for {RECORD_SECONDS} seconds...")\n\nframes = []\n\n# Record audio\nfor i in range(0, int(RESPEAKER_RATE / CHUNK * RECORD_SECONDS)):\n    data = stream.read(CHUNK)\n    frames.append(data)\n\nprint("Recording complete")\n\n# Stop stream\nstream.stop_stream()\nstream.close()\np.terminate()\n\n# Save as WAV file\nwf = wave.open(WAVE_OUTPUT_FILENAME, \'wb\')\nwf.setnchannels(RESPEAKER_CHANNELS)\nwf.setsampwidth(p.get_sample_size(p.get_format_from_width(RESPEAKER_WIDTH)))\nwf.setframerate(RESPEAKER_RATE)\nwf.writeframes(b\'\'.join(frames))\nwf.close()\n\nprint(f"Saved to {WAVE_OUTPUT_FILENAME}")\n'})}),"\n",(0,s.jsx)(n.p,{children:"Run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 capture_audio.py\naplay output.wav\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"part-3-beamforming-and-noise-cancellation",children:"Part 3: Beamforming and Noise Cancellation"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-access-dsp-parameters",children:"Step 1: Access DSP Parameters"}),"\n",(0,s.jsxs)(n.p,{children:["The ReSpeaker's XVSM-2000 DSP chip provides advanced audio processing. Access it via ",(0,s.jsx)(n.code,{children:"tuning.py"}),":"]}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.code,{children:"get_dsp_params.py"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nfrom tuning import Tuning\nimport usb.core\nimport usb.util\n\n# Find ReSpeaker device\ndev = usb.core.find(idVendor=0x2886, idProduct=0x0018)\nif not dev:\n    print("ReSpeaker not found!")\n    exit(1)\n\n# Initialize tuning interface\ntuning = Tuning(dev)\n\n# Read key DSP parameters\nprint(f"Direction of Arrival (DOA): {tuning.direction}")\nprint(f"Beamforming enabled: {tuning.read(\'STATNOISEONOFF\')}")\nprint(f"Noise suppression level: {tuning.read(\'NONSTATNOISEONOFF\')}")\nprint(f"Automatic Gain Control: {tuning.read(\'AGCONOFF\')}")\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Download tuning.py"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"wget https://raw.githubusercontent.com/respeaker/usb_4_mic_array/master/tuning.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 get_dsp_params.py\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Sample output"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Direction of Arrival (DOA): 120\nBeamforming enabled: 1\nNoise suppression level: 1\nAutomatic Gain Control: 1\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"DOA (Direction of Arrival)"})," indicates the angle (0-360\xb0) where the loudest sound is detected."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-2-enable-beamforming",children:"Step 2: Enable Beamforming"}),"\n",(0,s.jsx)(n.p,{children:"Beamforming combines signals from all microphones to focus on a specific direction, reducing noise from other angles."}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.code,{children:"enable_beamforming.py"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nfrom tuning import Tuning\nimport usb.core\n\ndev = usb.core.find(idVendor=0x2886, idProduct=0x0018)\ntuning = Tuning(dev)\n\n# Enable stationary noise suppression (fans, motors)\ntuning.write('STATNOISEONOFF', 1)\n\n# Enable non-stationary noise suppression (background speech)\ntuning.write('NONSTATNOISEONOFF', 1)\n\n# Enable automatic gain control\ntuning.write('AGCONOFF', 1)\n\n# Set maximum gain (dB) - adjust based on environment\ntuning.write('AGCMAXGAIN', 30)\n\n# Set noise suppression level (0-3, higher = more aggressive)\ntuning.write('SPEECHDETECTED', 2)\n\nprint(\"Beamforming and noise suppression enabled\")\nprint(f\"Current DOA: {tuning.direction}\xb0\")\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run before recording:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 enable_beamforming.py\npython3 capture_audio.py\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-3-real-time-doa-visualization",children:"Step 3: Real-Time DOA Visualization"}),"\n",(0,s.jsx)(n.p,{children:"Track speaker location in real-time:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nfrom tuning import Tuning\nfrom pixel_ring import pixel_ring\nimport usb.core\nimport time\n\ndev = usb.core.find(idVendor=0x2886, idProduct=0x0018)\ntuning = Tuning(dev)\n\npixel_ring.set_brightness(20)\n\nprint("Real-time DOA tracking (Ctrl+C to stop)...")\nprint("Speak to see the direction indicator")\n\ntry:\n    while True:\n        # Get direction of arrival (0-360\xb0)\n        direction = tuning.direction\n\n        # Convert to LED index (0-11 for 12 LEDs)\n        led_index = int((direction / 360.0) * 12) % 12\n\n        # Light up the LED pointing to speaker\n        pixel_ring.set_color_palette(led_index, 0x00FF00)  # Green\n        time.sleep(0.1)\n        pixel_ring.off()\n\nexcept KeyboardInterrupt:\n    pixel_ring.off()\n    print("\\nDOA tracking stopped")\n'})}),"\n",(0,s.jsx)(n.p,{children:"Run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 doa_tracking.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"Speak from different positions around the microphone - the green LED should point toward you."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"part-4-ros-2-integration",children:"Part 4: ROS 2 Integration"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-create-audio-publisher-node",children:"Step 1: Create Audio Publisher Node"}),"\n",(0,s.jsx)(n.p,{children:"Publish raw audio to a ROS 2 topic for processing by Whisper (next lesson)."}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.code,{children:"audio_publisher.py"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom audio_common_msgs.msg import AudioData\nimport pyaudio\nimport numpy as np\n\nclass AudioPublisher(Node):\n    def __init__(self):\n        super().__init__('audio_publisher')\n\n        # ROS 2 publisher\n        self.publisher_ = self.create_publisher(AudioData, 'audio/raw', 10)\n\n        # Audio configuration\n        self.RATE = 16000\n        self.CHANNELS = 6\n        self.CHUNK = 1024\n        self.DEVICE_INDEX = 1\n\n        # Initialize PyAudio\n        self.p = pyaudio.PyAudio()\n        self.stream = self.p.open(\n            rate=self.RATE,\n            format=pyaudio.paInt16,\n            channels=self.CHANNELS,\n            input=True,\n            input_device_index=self.DEVICE_INDEX,\n            frames_per_buffer=self.CHUNK,\n            stream_callback=self.audio_callback\n        )\n\n        self.get_logger().info('Audio publisher started')\n        self.stream.start_stream()\n\n    def audio_callback(self, in_data, frame_count, time_info, status):\n        # Publish audio data\n        msg = AudioData()\n        msg.data = list(in_data)\n        self.publisher_.publish(msg)\n\n        return (in_data, pyaudio.paContinue)\n\n    def destroy_node(self):\n        self.stream.stop_stream()\n        self.stream.close()\n        self.p.terminate()\n        super().destroy_node()\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = AudioPublisher()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-2-install-audio_common_msgs",children:"Step 2: Install audio_common_msgs"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt install ros-humble-audio-common-msgs\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-3-test-audio-stream",children:"Step 3: Test Audio Stream"}),"\n",(0,s.jsx)(n.p,{children:"Terminal 1:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash\npython3 audio_publisher.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"Terminal 2:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash\nros2 topic hz /audio/raw\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected output"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"average rate: 15.625\n  min: 0.064s max: 0.064s std dev: 0.00000s window: 16\n"})}),"\n",(0,s.jsx)(n.p,{children:"This confirms audio is streaming at ~16 Hz (1024 samples / 16000 Hz = 0.064s per chunk)."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-1-circular-buffer-recording",children:"Exercise 1: Circular Buffer Recording"}),"\n",(0,s.jsx)(n.p,{children:'Implement a circular buffer to continuously record the last 5 seconds of audio (useful for "wake word" detection).'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(n.code,{children:"collections.deque"})," with ",(0,s.jsx)(n.code,{children:"maxlen"})," for automatic buffer management"]}),"\n",(0,s.jsx)(n.li,{children:"Save buffer to file when a key is pressed"}),"\n",(0,s.jsx)(n.li,{children:"Display buffer fill percentage"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Starter code"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import pyaudio\nimport wave\nfrom collections import deque\nimport numpy as np\nimport threading\nimport sys\nimport termios\nimport tty\n\nRATE = 16000\nCHANNELS = 6\nCHUNK = 1024\nBUFFER_SECONDS = 5\n\n# Calculate buffer size\nbuffer_size = int(RATE / CHUNK * BUFFER_SECONDS)\naudio_buffer = deque(maxlen=buffer_size)\n\n# TODO: Implement circular buffer recording\n# 1. Continuously read from ReSpeaker\n# 2. Append chunks to deque\n# 3. On keypress, save deque contents to WAV\n# 4. Display buffer fill %\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solution approach"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Use threading for non-blocking keyboard input"}),"\n",(0,s.jsxs)(n.li,{children:["Convert deque to bytes with ",(0,s.jsx)(n.code,{children:"b''.join(audio_buffer)"})]}),"\n",(0,s.jsxs)(n.li,{children:["Write to WAV file with ",(0,s.jsx)(n.code,{children:"wave"})," module"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"exercise-2-voice-activity-detection-vad",children:"Exercise 2: Voice Activity Detection (VAD)"}),"\n",(0,s.jsx)(n.p,{children:"Implement simple energy-based VAD to detect when someone is speaking."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Algorithm"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Calculate RMS (root mean square) energy of each audio chunk"}),"\n",(0,s.jsx)(n.li,{children:'If energy > threshold, mark as "speech"'}),"\n",(0,s.jsx)(n.li,{children:"Use LED ring to indicate speech detection (green) vs. silence (red)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Starter code"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def calculate_rms(audio_data):\n    """Calculate RMS energy of audio chunk"""\n    # TODO: Convert bytes to numpy array\n    # TODO: Calculate RMS = sqrt(mean(samples^2))\n    pass\n\ndef is_speech(rms_energy, threshold=500):\n    """Determine if chunk contains speech"""\n    # TODO: Compare energy to threshold\n    pass\n\n# Main loop\nwhile True:\n    data = stream.read(CHUNK)\n    energy = calculate_rms(data)\n\n    if is_speech(energy):\n        # TODO: Set LED ring green\n        pass\n    else:\n        # TODO: Set LED ring red\n        pass\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hint"}),": Use ",(0,s.jsx)(n.code,{children:"np.frombuffer(data, dtype=np.int16)"})," to convert bytes to NumPy array."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"issue-1-respeaker-not-found-error",children:'Issue 1: "ReSpeaker not found" error'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": USB device not properly detected"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Check USB connection (try a different port)"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Verify with ",(0,s.jsx)(n.code,{children:"lsusb | grep 2886:0018"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Add user to ",(0,s.jsx)(n.code,{children:"audio"})," group:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo usermod -a -G audio $USER\n"})}),"\n",(0,s.jsx)(n.p,{children:"Log out and back in for changes to take effect"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Check permissions:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ls -l /dev/snd/\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You should have read/write access to ",(0,s.jsx)(n.code,{children:"pcmC*D*c"})," devices"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"issue-2-input-overflowed-warning",children:'Issue 2: "Input overflowed" warning'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": System can't keep up with 16 kHz sampling rate (buffer overruns)"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Increase ",(0,s.jsx)(n.code,{children:"CHUNK"})," size (1024 \u2192 2048)"]}),"\n",(0,s.jsx)(n.li,{children:"Close resource-intensive applications"}),"\n",(0,s.jsx)(n.li,{children:"Use a dedicated USB 2.0 port (not a hub)"}),"\n",(0,s.jsxs)(n.li,{children:["Increase process priority:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo nice -n -10 python3 capture_audio.py\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"issue-3-poor-audio-quality-with-noise",children:"Issue 3: Poor audio quality with noise"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": Beamforming not enabled or incorrect DSP settings"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Run ",(0,s.jsx)(n.code,{children:"enable_beamforming.py"})," before recording"]}),"\n",(0,s.jsxs)(n.li,{children:["Adjust noise suppression level (try 0, 1, 2, 3):","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"tuning.write('SPEECHDETECTED', 3)  # Max suppression\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Check AGC gain (too high = amplified noise):","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"tuning.write('AGCMAXGAIN', 20)  # Lower gain\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"issue-4-leds-not-working",children:"Issue 4: LEDs not working"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause"}),": Missing ",(0,s.jsx)(n.code,{children:"hidapi"})," library or permission issues"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Install hidapi:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt install libhidapi-libusb0 libhidapi-dev\npip3 install hidapi\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Add udev rule for USB access:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'echo \'SUBSYSTEM=="usb", ATTR{idVendor}=="2886", ATTR{idProduct}=="0018", MODE="0666"\' | \\\nsudo tee /etc/udev/rules.d/99-respeaker.rules\nsudo udevadm control --reload-rules\n'})}),"\n",(0,s.jsx)(n.p,{children:"Unplug and replug the ReSpeaker"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"latency-reduction",children:"Latency Reduction"}),"\n",(0,s.jsx)(n.p,{children:"For real-time applications (e.g., conversational AI), minimize latency:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reduce buffer size"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"CHUNK = 512  # 32ms latency at 16 kHz\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["Use ",(0,s.jsx)(n.code,{children:"stream_callback"})]})," (non-blocking):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"stream = p.open(..., stream_callback=audio_callback)\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Pin to CPU core"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"taskset -c 0 python3 audio_publisher.py\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Latency budget"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Audio capture: 32 ms"}),"\n",(0,s.jsx)(n.li,{children:"Beamforming (DSP): 10 ms"}),"\n",(0,s.jsx)(n.li,{children:"ROS 2 publish: 5 ms"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Total"}),": ~50 ms (acceptable for conversational AI)"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"multi-microphone-processing",children:"Multi-Microphone Processing"}),"\n",(0,s.jsx)(n.p,{children:"For advanced applications, process individual microphone channels separately:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Record all 6 channels\nstream = p.open(..., channels=6)\ndata = stream.read(CHUNK)\n\n# Convert to numpy array (interleaved samples)\nsamples = np.frombuffer(data, dtype=np.int16)\n\n# De-interleave into separate channels\nchannels = samples.reshape(-1, 6).T  # Shape: (6, CHUNK)\n\n# Access individual microphones\nmic_0 = channels[0]  # First microphone\nmic_1 = channels[1]  # Second microphone\n# ... etc.\n\n# Apply custom beamforming (e.g., delay-and-sum)\nbeamformed = np.mean(channels, axis=0)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"In this lesson, you learned to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u2705 Set up ReSpeaker USB microphone arrays for robotics"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Configure ALSA and PyAudio for 16 kHz, 6-channel recording"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Enable DSP-based beamforming and noise cancellation"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Implement real-time DOA tracking with LED feedback"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Integrate audio capture with ROS 2 for downstream processing"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Far-field audio capture requires beamforming to reject noise"}),"\n",(0,s.jsx)(n.li,{children:"The ReSpeaker's onboard DSP handles heavy lifting (no CPU overhead)"}),"\n",(0,s.jsx)(n.li,{children:"16 kHz sample rate is optimal for speech (balance quality vs. bandwidth)"}),"\n",(0,s.jsx)(n.li,{children:'Circular buffers enable "always listening" with on-demand saving'}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,s.jsx)(n.h3,{id:"official-documentation",children:"Official Documentation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://wiki.seeedstudio.com/ReSpeaker_Mic_Array_v2.0/",children:"ReSpeaker Mic Array v2.0 Wiki"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://people.csail.mit.edu/hubert/pyaudio/docs/",children:"PyAudio Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.alsa-project.org/",children:"ALSA Project"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"research-papers",children:"Research Papers"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://ieeexplore.ieee.org/document/7471644",children:"Beamforming for Speech Recognition"})," - Overview of beamforming techniques"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/2011.01480",children:"Voice Activity Detection Survey"})," - Modern VAD approaches"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"code-examples",children:"Code Examples"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://github.com/respeaker/usb_4_mic_array/tree/master/examples",children:"ReSpeaker Examples"})," - Official example scripts"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://github.com/ros-drivers/audio_common",children:"ROS 2 Audio Tools"})," - Audio common messages and utilities"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"video-tutorials",children:"Video Tutorials"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://www.youtube.com/watch?v=_example",children:"ReSpeaker Setup Tutorial"})," - Hardware setup walkthrough"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://www.youtube.com/watch?v=_example",children:"Beamforming Explained"})," - Visual explanation of beamforming"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"next-lesson",children:"Next Lesson"}),"\n",(0,s.jsxs)(n.p,{children:["In ",(0,s.jsx)(n.strong,{children:"Lesson 2: Speech-to-Text with Whisper"}),", you'll learn to:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Run OpenAI's Whisper model for offline speech recognition"}),"\n",(0,s.jsx)(n.li,{children:"Optimize Whisper for real-time inference on edge devices"}),"\n",(0,s.jsx)(n.li,{children:"Integrate with ROS 2 for voice command processing"}),"\n",(0,s.jsx)(n.li,{children:"Handle multilingual and noisy audio inputs"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Continue to ",(0,s.jsx)(n.a,{href:"/physical-ai-humanoid-robotics/docs/module-4-vla/ch11-whisper/whisper-api",children:"Speech-to-Text with Whisper \u2192"})]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var r=i(6540);const s={},a=r.createContext(s);function l(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);