"use strict";(globalThis.webpackChunkphysical_ai_course=globalThis.webpackChunkphysical_ai_course||[]).push([[194],{1793:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"module-4-vla/ch11-whisper/command-parsing","title":"Voice Command Parsing: Intent and Slot Extraction","description":"Learning Objectives","source":"@site/docs/module-4-vla/ch11-whisper/command-parsing.md","sourceDirName":"module-4-vla/ch11-whisper","slug":"/module-4-vla/ch11-whisper/command-parsing","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch11-whisper/command-parsing","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/ch11-whisper/command-parsing.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Local Speech-to-Text Pipeline with Whisper","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch11-whisper/speech-to-text"},"next":{"title":"LLM Integration for Cognitive Robot Planning","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch12-llm-planning/llm-integration"}}');var s=t(4848),r=t(8453);const a={},o="Voice Command Parsing: Intent and Slot Extraction",c={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Part 1: Rule-Based Command Parsing",id:"part-1-rule-based-command-parsing",level:2},{value:"Step 1: Define Command Grammar",id:"step-1-define-command-grammar",level:3},{value:"Step 2: Regex-Based Parser",id:"step-2-regex-based-parser",level:3},{value:"Step 3: Compound Command Parsing",id:"step-3-compound-command-parsing",level:3},{value:"Part 2: NLU with spaCy",id:"part-2-nlu-with-spacy",level:2},{value:"Step 1: Install spaCy",id:"step-1-install-spacy",level:3},{value:"Step 2: Entity Extraction",id:"step-2-entity-extraction",level:3},{value:"Step 3: Intent Classification",id:"step-3-intent-classification",level:3},{value:"Part 3: Mapping to ROS 2 Actions",id:"part-3-mapping-to-ros-2-actions",level:2},{value:"Step 1: Define ROS 2 Action Messages",id:"step-1-define-ros-2-action-messages",level:3},{value:"Step 2: Command-to-Action Mapper",id:"step-2-command-to-action-mapper",level:3},{value:"Step 3: Complete Voice Command Pipeline",id:"step-3-complete-voice-command-pipeline",level:3},{value:"Part 4: Handling Ambiguity",id:"part-4-handling-ambiguity",level:2},{value:"Step 1: Clarification Dialogs",id:"step-1-clarification-dialogs",level:3},{value:"Step 2: Contextual Pronoun Resolution",id:"step-2-contextual-pronoun-resolution",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Exercise 1: Manipulation Command Parser",id:"exercise-1-manipulation-command-parser",level:3},{value:"Exercise 2: Confidence-Based Fallback",id:"exercise-2-confidence-based-fallback",level:3},{value:"Summary",id:"summary",level:2},{value:"Additional Resources",id:"additional-resources",level:2},{value:"Official Documentation",id:"official-documentation",level:3},{value:"NLU Training",id:"nlu-training",level:3},{value:"Research Papers",id:"research-papers",level:3},{value:"Next Lesson",id:"next-lesson",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"voice-command-parsing-intent-and-slot-extraction",children:"Voice Command Parsing: Intent and Slot Extraction"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Extract intent (action) and entities (slots) from voice transcripts"}),"\n",(0,s.jsx)(e.li,{children:"Implement rule-based parsers for structured robotics commands"}),"\n",(0,s.jsx)(e.li,{children:"Use spaCy for natural language understanding (NLU)"}),"\n",(0,s.jsx)(e.li,{children:"Map parsed commands to ROS 2 action messages"}),"\n",(0,s.jsx)(e.li,{children:"Handle ambiguous commands with clarification dialogs"}),"\n",(0,s.jsx)(e.li,{children:"Build a complete voice\u2192command\u2192action pipeline"}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Required Knowledge"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Python programming (regex, classes)"}),"\n",(0,s.jsx)(e.li,{children:"Basic NLP concepts (tokenization, named entities)"}),"\n",(0,s.jsx)(e.li,{children:"ROS 2 actions and services"}),"\n",(0,s.jsxs)(e.li,{children:["Completion of ",(0,s.jsx)(e.a,{href:"/physical-ai-humanoid-robotics/docs/module-4-vla/ch11-whisper/speech-to-text",children:"Lesson 3: Speech-to-Text"})]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Required Software"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Python 3.10+"}),"\n",(0,s.jsxs)(e.li,{children:["spaCy (",(0,s.jsx)(e.code,{children:"python3 -m spacy download en_core_web_sm"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"ROS 2 Humble"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Estimated Time"}),": 3-4 hours"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(e.p,{children:["Raw speech transcripts like ",(0,s.jsx)(e.strong,{children:'"Move forward three meters and turn left"'})," must be parsed into structured commands:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-json",children:'{\n  "intent": "navigate",\n  "actions": [\n    {\n      "type": "move",\n      "direction": "forward",\n      "distance": 3.0,\n      "unit": "meters"\n    },\n    {\n      "type": "turn",\n      "direction": "left",\n      "angle": 90.0,\n      "unit": "degrees"\n    }\n  ]\n}\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Command parsing challenges"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Ambiguity"}),': "Go to the table" (which table? how?)']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Variation"}),': "Move ahead 3m" vs. "Go forward three meters"']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Compound commands"}),': "Pick up the cube and place it on the shelf"']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Contextual pronouns"}),': "Grab it" (what is "it"?)']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Units"}),': "Move 5 feet" vs. "Move 1.5 meters"']}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Approaches"}),":"]}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Approach"}),(0,s.jsx)(e.th,{children:"Pros"}),(0,s.jsx)(e.th,{children:"Cons"}),(0,s.jsx)(e.th,{children:"Best For"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Rule-based (regex)"})}),(0,s.jsx)(e.td,{children:"Fast, deterministic, no training"}),(0,s.jsx)(e.td,{children:"Brittle, doesn't generalize"}),(0,s.jsx)(e.td,{children:"Structured commands (factories)"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"NLU (spaCy)"})}),(0,s.jsx)(e.td,{children:"Handles variation, entities"}),(0,s.jsx)(e.td,{children:"Requires training for domain"}),(0,s.jsx)(e.td,{children:"Semi-structured (research labs)"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"LLM (GPT-4)"})}),(0,s.jsx)(e.td,{children:"Most flexible, few-shot"}),(0,s.jsx)(e.td,{children:"Slow, expensive, unreliable"}),(0,s.jsx)(e.td,{children:"Open-ended tasks (next lesson)"})]})]})]}),"\n",(0,s.jsxs)(e.p,{children:["This lesson focuses on ",(0,s.jsx)(e.strong,{children:"rule-based + spaCy"})," for deterministic, low-latency parsing. Lesson 12 covers LLM-based parsing for complex tasks."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"part-1-rule-based-command-parsing",children:"Part 1: Rule-Based Command Parsing"}),"\n",(0,s.jsx)(e.h3,{id:"step-1-define-command-grammar",children:"Step 1: Define Command Grammar"}),"\n",(0,s.jsx)(e.p,{children:"Start with structured command templates:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Navigation commands"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"move {direction} {distance} {unit}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"turn {direction} [{angle} degrees]"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"go to {location}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"stop"})}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Manipulation commands"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"pick up {object}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"place {object} on {location}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"grab {object}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"release"})}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Perception commands"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"look at {object}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"find {object}"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.code,{children:"scan the area"})}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-2-regex-based-parser",children:"Step 2: Regex-Based Parser"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport re\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\n@dataclass\nclass NavigationCommand:\n    """Structured navigation command"""\n    action: str  # move, turn, stop, go_to\n    direction: Optional[str] = None  # forward, backward, left, right\n    distance: Optional[float] = None\n    angle: Optional[float] = None\n    location: Optional[str] = None\n\nclass CommandParser:\n    def __init__(self):\n        # Define regex patterns for each command type\n        self.patterns = {\n            # Movement: "move forward 3 meters"\n            \'move\': re.compile(\n                r\'move\\s+(forward|backward|ahead|back)\\s+(\\d+\\.?\\d*)\\s*(meters?|m|feet|ft)\',\n                re.IGNORECASE\n            ),\n\n            # Turn: "turn left 90 degrees" or "turn right"\n            \'turn\': re.compile(\n                r\'turn\\s+(left|right)(?:\\s+(\\d+\\.?\\d*)\\s*degrees?)?\',\n                re.IGNORECASE\n            ),\n\n            # Go to: "go to the kitchen"\n            \'go_to\': re.compile(\n                r\'go\\s+to\\s+(?:the\\s+)?(\\w+)\',\n                re.IGNORECASE\n            ),\n\n            # Stop: "stop" or "halt"\n            \'stop\': re.compile(\n                r\'\\b(stop|halt|freeze)\\b\',\n                re.IGNORECASE\n            )\n        }\n\n    def parse(self, transcript: str) -> Optional[NavigationCommand]:\n        """Parse transcript into NavigationCommand"""\n\n        # Try each pattern\n        for action, pattern in self.patterns.items():\n            match = pattern.search(transcript)\n            if match:\n                return self._extract_command(action, match)\n\n        return None  # No match found\n\n    def _extract_command(self, action: str, match) -> NavigationCommand:\n        """Extract command from regex match"""\n\n        if action == \'move\':\n            direction = match.group(1).lower()\n            # Normalize "ahead" -> "forward", "back" -> "backward"\n            direction = \'forward\' if direction == \'ahead\' else direction\n            direction = \'backward\' if direction == \'back\' else direction\n\n            distance = float(match.group(2))\n\n            # Convert units to meters\n            unit = match.group(3).lower()\n            if \'feet\' in unit or unit == \'ft\':\n                distance *= 0.3048  # feet to meters\n\n            return NavigationCommand(\n                action=\'move\',\n                direction=direction,\n                distance=distance\n            )\n\n        elif action == \'turn\':\n            direction = match.group(1).lower()\n            angle = float(match.group(2)) if match.group(2) else 90.0  # Default 90\xb0\n\n            return NavigationCommand(\n                action=\'turn\',\n                direction=direction,\n                angle=angle\n            )\n\n        elif action == \'go_to\':\n            location = match.group(1).lower()\n\n            return NavigationCommand(\n                action=\'go_to\',\n                location=location\n            )\n\n        elif action == \'stop\':\n            return NavigationCommand(action=\'stop\')\n\n        return None\n\n# Usage\nparser = CommandParser()\n\ncommands = [\n    "Move forward 3 meters",\n    "turn left 45 degrees",\n    "go to the kitchen",\n    "stop",\n    "move ahead 5 feet"  # Converts to meters\n]\n\nfor cmd in commands:\n    result = parser.parse(cmd)\n    print(f"\'{cmd}\' -> {result}")\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"'Move forward 3 meters' -> NavigationCommand(action='move', direction='forward', distance=3.0, angle=None, location=None)\n'turn left 45 degrees' -> NavigationCommand(action='turn', direction='left', distance=None, angle=45.0, location=None)\n'go to the kitchen' -> NavigationCommand(action='go_to', direction=None, distance=None, angle=None, location='kitchen')\n'stop' -> NavigationCommand(action='stop', direction=None, distance=None, angle=None, location=None)\n'move ahead 5 feet' -> NavigationCommand(action='move', direction='forward', distance=1.524, angle=None, location=None)\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-3-compound-command-parsing",children:"Step 3: Compound Command Parsing"}),"\n",(0,s.jsx)(e.p,{children:"Handle commands with multiple actions:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import re\n\nclass CompoundCommandParser:\n    def __init__(self):\n        self.parser = CommandParser()\n\n        # Conjunctions that separate commands\n        self.conjunctions = r'\\s+(and|then|after that)\\s+'\n\n    def parse(self, transcript: str) -> List[NavigationCommand]:\n        \"\"\"Parse compound commands separated by 'and', 'then', etc.\"\"\"\n\n        # Split on conjunctions\n        parts = re.split(self.conjunctions, transcript, flags=re.IGNORECASE)\n\n        # Filter out conjunction words\n        command_parts = [p for p in parts if p.lower() not in ['and', 'then', 'after that']]\n\n        # Parse each part\n        commands = []\n        for part in command_parts:\n            cmd = self.parser.parse(part)\n            if cmd:\n                commands.append(cmd)\n\n        return commands\n\n# Usage\nparser = CompoundCommandParser()\n\ntranscript = \"Move forward 3 meters and turn left 90 degrees\"\ncommands = parser.parse(transcript)\n\nfor i, cmd in enumerate(commands):\n    print(f\"Step {i+1}: {cmd}\")\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Step 1: NavigationCommand(action='move', direction='forward', distance=3.0, ...)\nStep 2: NavigationCommand(action='turn', direction='left', angle=90.0, ...)\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"part-2-nlu-with-spacy",children:"Part 2: NLU with spaCy"}),"\n",(0,s.jsx)(e.p,{children:"For more flexible parsing with entity recognition:"}),"\n",(0,s.jsx)(e.h3,{id:"step-1-install-spacy",children:"Step 1: Install spaCy"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"pip3 install spacy\n\n# Download English language model\npython3 -m spacy download en_core_web_sm\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-2-entity-extraction",children:"Step 2: Entity Extraction"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport spacy\n\n# Load spaCy model\nnlp = spacy.load("en_core_web_sm")\n\ndef extract_entities(transcript: str):\n    """Extract entities from transcript using spaCy"""\n    doc = nlp(transcript)\n\n    entities = {\n        "numbers": [],\n        "objects": [],\n        "locations": [],\n        "directions": []\n    }\n\n    # Extract numeric values\n    for token in doc:\n        if token.like_num:\n            entities["numbers"].append(float(token.text))\n\n    # Extract named entities\n    for ent in doc.ents:\n        if ent.label_ == "CARDINAL":  # Numbers\n            entities["numbers"].append(ent.text)\n        elif ent.label_ in ["GPE", "LOC", "FAC"]:  # Locations\n            entities["locations"].append(ent.text)\n\n    # Extract direction words (custom dictionary)\n    direction_words = {"forward", "backward", "left", "right", "up", "down"}\n    for token in doc:\n        if token.text.lower() in direction_words:\n            entities["directions"].append(token.text.lower())\n\n    # Extract object nouns (potential manipulation targets)\n    for token in doc:\n        if token.pos_ == "NOUN" and token.dep_ in ["dobj", "pobj"]:\n            entities["objects"].append(token.text.lower())\n\n    return entities\n\n# Usage\ntranscripts = [\n    "Move forward three meters",\n    "Pick up the red cube on the table",\n    "Go to the kitchen and find the cup"\n]\n\nfor transcript in transcripts:\n    entities = extract_entities(transcript)\n    print(f"\\n\'{transcript}\'")\n    print(f"  Numbers: {entities[\'numbers\']}")\n    print(f"  Objects: {entities[\'objects\']}")\n    print(f"  Locations: {entities[\'locations\']}")\n    print(f"  Directions: {entities[\'directions\']}")\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"'Move forward three meters'\n  Numbers: ['three']\n  Objects: ['meters']\n  Locations: []\n  Directions: ['forward']\n\n'Pick up the red cube on the table'\n  Numbers: []\n  Objects: ['cube', 'table']\n  Locations: []\n  Directions: []\n\n'Go to the kitchen and find the cup'\n  Numbers: []\n  Objects: ['cup']\n  Locations: []\n  Directions: []\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-3-intent-classification",children:"Step 3: Intent Classification"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from dataclasses import dataclass\nfrom typing import List, Dict\n\n@dataclass\nclass ParsedCommand:\n    intent: str  # navigate, manipulate, perceive\n    entities: Dict[str, List]\n    confidence: float\n\nclass IntentClassifier:\n    def __init__(self):\n        # Intent keywords\n        self.intent_keywords = {\n            \'navigate\': [\'move\', \'go\', \'turn\', \'walk\', \'navigate\', \'drive\', \'stop\'],\n            \'manipulate\': [\'pick\', \'grab\', \'place\', \'put\', \'drop\', \'release\', \'grasp\'],\n            \'perceive\': [\'look\', \'find\', \'search\', \'scan\', \'detect\', \'see\']\n        }\n\n        self.nlp = spacy.load("en_core_web_sm")\n\n    def classify(self, transcript: str) -> ParsedCommand:\n        """Classify intent and extract entities"""\n        doc = self.nlp(transcript)\n\n        # Extract entities\n        entities = self._extract_entities(doc)\n\n        # Classify intent by keyword matching\n        intent, confidence = self._classify_intent(doc)\n\n        return ParsedCommand(\n            intent=intent,\n            entities=entities,\n            confidence=confidence\n        )\n\n    def _extract_entities(self, doc) -> Dict[str, List]:\n        """Extract all relevant entities"""\n        entities = {\n            "numbers": [],\n            "objects": [],\n            "locations": [],\n            "directions": [],\n            "colors": []\n        }\n\n        # Numbers\n        for token in doc:\n            if token.like_num or token.pos_ == "NUM":\n                try:\n                    entities["numbers"].append(float(token.text))\n                except:\n                    pass\n\n        # Directions\n        direction_words = {"forward", "backward", "left", "right", "up", "down", "ahead", "back"}\n        for token in doc:\n            if token.text.lower() in direction_words:\n                entities["directions"].append(token.text.lower())\n\n        # Colors\n        color_words = {"red", "blue", "green", "yellow", "black", "white", "orange", "purple"}\n        for token in doc:\n            if token.text.lower() in color_words:\n                entities["colors"].append(token.text.lower())\n\n        # Objects (nouns that are direct/indirect objects)\n        for token in doc:\n            if token.pos_ == "NOUN" and token.dep_ in ["dobj", "pobj", "nsubj"]:\n                # Skip location words\n                if token.text.lower() not in ["kitchen", "room", "table", "shelf"]:\n                    entities["objects"].append(token.text.lower())\n\n        # Locations\n        location_words = {"kitchen", "room", "table", "shelf", "floor", "counter"}\n        for token in doc:\n            if token.text.lower() in location_words:\n                entities["locations"].append(token.text.lower())\n\n        return entities\n\n    def _classify_intent(self, doc) -> tuple:\n        """Classify intent based on verb keywords"""\n        scores = {intent: 0 for intent in self.intent_keywords}\n\n        # Check each token against intent keywords\n        for token in doc:\n            for intent, keywords in self.intent_keywords.items():\n                if token.lemma_.lower() in keywords:\n                    scores[intent] += 1\n\n        # Get intent with highest score\n        if max(scores.values()) == 0:\n            return "unknown", 0.0\n\n        intent = max(scores, key=scores.get)\n        confidence = scores[intent] / len(doc)  # Normalize by doc length\n\n        return intent, confidence\n\n# Usage\nclassifier = IntentClassifier()\n\ncommands = [\n    "Move forward three meters and turn left",\n    "Pick up the red cube on the table",\n    "Look for the blue ball",\n    "Go to the kitchen and grab the cup"\n]\n\nfor cmd in commands:\n    result = classifier.classify(cmd)\n    print(f"\\n\'{cmd}\'")\n    print(f"  Intent: {result.intent} (confidence: {result.confidence:.2f})")\n    print(f"  Entities: {result.entities}")\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"'Move forward three meters and turn left'\n  Intent: navigate (confidence: 0.22)\n  Entities: {'numbers': [3.0], 'directions': ['forward', 'left'], ...}\n\n'Pick up the red cube on the table'\n  Intent: manipulate (confidence: 0.14)\n  Entities: {'colors': ['red'], 'objects': ['cube'], 'locations': ['table'], ...}\n\n'Look for the blue ball'\n  Intent: perceive (confidence: 0.20)\n  Entities: {'colors': ['blue'], 'objects': ['ball'], ...}\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"part-3-mapping-to-ros-2-actions",children:"Part 3: Mapping to ROS 2 Actions"}),"\n",(0,s.jsx)(e.h3,{id:"step-1-define-ros-2-action-messages",children:"Step 1: Define ROS 2 Action Messages"}),"\n",(0,s.jsxs)(e.p,{children:["Create custom action for navigation (in ",(0,s.jsx)(e.code,{children:"my_robot_interfaces"})," package):"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.code,{children:"NavigateToGoal.action"})}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"# Goal\nstring command_type  # move, turn, go_to\nfloat32 distance     # meters\nfloat32 angle        # degrees\nstring location      # target location name\n---\n# Result\nbool success\nstring message\n---\n# Feedback\nfloat32 distance_remaining\nfloat32 current_heading\n"})}),"\n",(0,s.jsx)(e.p,{children:"Build:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"colcon build --packages-select my_robot_interfaces\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-2-command-to-action-mapper",children:"Step 2: Command-to-Action Mapper"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionClient\nfrom my_robot_interfaces.action import NavigateToGoal\nfrom std_msgs.msg import String\n\nclass CommandToActionMapper(Node):\n    def __init__(self):\n        super().__init__('command_to_action_mapper')\n\n        # Subscribe to parsed commands (from previous stage)\n        self.cmd_sub = self.create_subscription(\n            String,\n            'voice/parsed_command',\n            self.command_callback,\n            10\n        )\n\n        # Action client for navigation\n        self.nav_client = ActionClient(\n            self,\n            NavigateToGoal,\n            'navigate_to_goal'\n        )\n\n        self.get_logger().info('Command-to-Action Mapper ready')\n\n    def command_callback(self, msg: String):\n        \"\"\"Convert parsed command JSON to ROS 2 action\"\"\"\n        import json\n\n        try:\n            command = json.loads(msg.data)\n            self.execute_command(command)\n        except Exception as e:\n            self.get_logger().error(f'Invalid command: {e}')\n\n    def execute_command(self, command: dict):\n        \"\"\"Execute parsed command as ROS 2 action\"\"\"\n        if command['intent'] == 'navigate':\n            for action in command.get('actions', []):\n                self.send_navigation_goal(action)\n\n    def send_navigation_goal(self, action: dict):\n        \"\"\"Send navigation goal to action server\"\"\"\n        # Wait for action server\n        self.nav_client.wait_for_server()\n\n        # Create goal message\n        goal_msg = NavigateToGoal.Goal()\n        goal_msg.command_type = action['type']  # move, turn, go_to\n\n        if 'distance' in action:\n            goal_msg.distance = action['distance']\n        if 'angle' in action:\n            goal_msg.angle = action['angle']\n        if 'location' in action:\n            goal_msg.location = action['location']\n\n        self.get_logger().info(f'Sending goal: {action}')\n\n        # Send goal asynchronously\n        send_goal_future = self.nav_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.feedback_callback\n        )\n\n        send_goal_future.add_done_callback(self.goal_response_callback)\n\n    def goal_response_callback(self, future):\n        \"\"\"Handle goal acceptance/rejection\"\"\"\n        goal_handle = future.result()\n\n        if not goal_handle.accepted:\n            self.get_logger().warn('Goal rejected')\n            return\n\n        self.get_logger().info('Goal accepted, executing...')\n\n        # Get result\n        result_future = goal_handle.get_result_async()\n        result_future.add_done_callback(self.result_callback)\n\n    def feedback_callback(self, feedback_msg):\n        \"\"\"Handle action feedback\"\"\"\n        feedback = feedback_msg.feedback\n        self.get_logger().info(\n            f'Distance remaining: {feedback.distance_remaining:.2f}m'\n        )\n\n    def result_callback(self, future):\n        \"\"\"Handle action result\"\"\"\n        result = future.result().result\n\n        if result.success:\n            self.get_logger().info(f'Action completed: {result.message}')\n        else:\n            self.get_logger().error(f'Action failed: {result.message}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CommandToActionMapper()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-3-complete-voice-command-pipeline",children:"Step 3: Complete Voice Command Pipeline"}),"\n",(0,s.jsx)(e.p,{children:"Integrate all components:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport json\nfrom command_parser import IntentClassifier\n\nclass VoiceCommandPipeline(Node):\n    def __init__(self):\n        super().__init__('voice_command_pipeline')\n\n        # Initialize parser\n        self.classifier = IntentClassifier()\n\n        # Subscribe to transcripts (from Whisper)\n        self.transcript_sub = self.create_subscription(\n            String,\n            'voice/transcript',\n            self.transcript_callback,\n            10\n        )\n\n        # Publish parsed commands\n        self.command_pub = self.create_publisher(\n            String,\n            'voice/parsed_command',\n            10\n        )\n\n        self.get_logger().info('Voice Command Pipeline started')\n\n    def transcript_callback(self, msg: String):\n        \"\"\"Parse transcript and publish structured command\"\"\"\n        transcript = msg.data\n        self.get_logger().info(f'Transcript: {transcript}')\n\n        # Parse with NLU\n        result = self.classifier.classify(transcript)\n\n        if result.intent == \"unknown\":\n            self.get_logger().warn(f'Unknown command: {transcript}')\n            return\n\n        # Convert to JSON\n        command_json = json.dumps({\n            \"intent\": result.intent,\n            \"entities\": result.entities,\n            \"confidence\": result.confidence,\n            \"original_text\": transcript\n        })\n\n        # Publish\n        cmd_msg = String()\n        cmd_msg.data = command_json\n        self.command_pub.publish(cmd_msg)\n\n        self.get_logger().info(f'Parsed: {result.intent} ({result.confidence:.2f})')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = VoiceCommandPipeline()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Launch file"})," (",(0,s.jsx)(e.code,{children:"voice_pipeline.launch.py"}),"):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # 1. Audio capture\n        Node(\n            package='voice_control',\n            executable='audio_publisher.py',\n            name='audio_publisher'\n        ),\n\n        # 2. Whisper transcription\n        Node(\n            package='voice_control',\n            executable='local_whisper_node.py',\n            name='whisper_node'\n        ),\n\n        # 3. Command parsing\n        Node(\n            package='voice_control',\n            executable='voice_command_pipeline.py',\n            name='command_parser'\n        ),\n\n        # 4. Command-to-action mapping\n        Node(\n            package='voice_control',\n            executable='command_to_action_mapper.py',\n            name='action_mapper'\n        )\n    ])\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Launch"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 launch voice_control voice_pipeline.launch.py\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Test"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Speak: "Move forward three meters"\n# Expected ROS 2 topic flow:\n# /audio/raw \u2192 /voice/transcript \u2192 /voice/parsed_command \u2192 NavigateToGoal action\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"part-4-handling-ambiguity",children:"Part 4: Handling Ambiguity"}),"\n",(0,s.jsx)(e.h3,{id:"step-1-clarification-dialogs",children:"Step 1: Clarification Dialogs"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class AmbiguityResolver:\n    def __init__(self, node):\n        self.node = node\n\n        # Publisher for clarification questions\n        self.question_pub = node.create_publisher(\n            String,\n            'voice/clarification_question',\n            10\n        )\n\n        # Subscriber for clarification responses\n        self.response_sub = node.create_subscription(\n            String,\n            'voice/clarification_response',\n            self.response_callback,\n            10\n        )\n\n        self.pending_command = None\n\n    def check_ambiguity(self, command: dict) -> bool:\n        \"\"\"Return True if command is ambiguous\"\"\"\n        entities = command['entities']\n\n        # Check for missing required parameters\n        if command['intent'] == 'manipulate':\n            if not entities.get('objects'):\n                self.ask_clarification(\"Which object should I pick up?\")\n                self.pending_command = command\n                return True\n\n            if len(entities['objects']) > 1 and not entities.get('colors'):\n                objects = entities['objects']\n                self.ask_clarification(\n                    f\"I see multiple objects: {', '.join(objects)}. Which one?\"\n                )\n                self.pending_command = command\n                return True\n\n        return False\n\n    def ask_clarification(self, question: str):\n        \"\"\"Publish clarification question\"\"\"\n        msg = String()\n        msg.data = question\n        self.question_pub.publish(msg)\n        self.node.get_logger().info(f'Asking: {question}')\n\n    def response_callback(self, msg: String):\n        \"\"\"Handle clarification response\"\"\"\n        response = msg.data.lower()\n\n        if self.pending_command:\n            # Update command with clarification\n            # (Implementation depends on command structure)\n            self.node.get_logger().info(f'Clarification received: {response}')\n            # ... update pending_command and execute\n            self.pending_command = None\n\n# Usage in VoiceCommandPipeline\nresolver = AmbiguityResolver(self)\n\nif resolver.check_ambiguity(command):\n    return  # Wait for clarification\n\n# Otherwise, proceed with command\nself.command_pub.publish(cmd_msg)\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"step-2-contextual-pronoun-resolution",children:"Step 2: Contextual Pronoun Resolution"}),"\n",(0,s.jsx)(e.p,{children:'Track previous commands to resolve "it", "there", etc.:'}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'class ContextTracker:\n    def __init__(self):\n        self.last_object = None\n        self.last_location = None\n\n    def update(self, command: dict):\n        """Update context from executed command"""\n        entities = command[\'entities\']\n\n        if entities.get(\'objects\'):\n            self.last_object = entities[\'objects\'][0]\n\n        if entities.get(\'locations\'):\n            self.last_location = entities[\'locations\'][0]\n\n    def resolve_pronouns(self, transcript: str) -> str:\n        """Replace pronouns with contextual references"""\n        # Replace "it" with last object\n        if "it" in transcript.lower() and self.last_object:\n            transcript = transcript.replace("it", self.last_object)\n\n        # Replace "there" with last location\n        if "there" in transcript.lower() and self.last_location:\n            transcript = transcript.replace("there", self.last_location)\n\n        return transcript\n\n# Usage\ncontext = ContextTracker()\n\n# First command: "Pick up the cube"\nresult = classifier.classify("Pick up the cube")\ncontext.update({"entities": result.entities})\n\n# Second command: "Place it on the table"\ntranscript2 = "Place it on the table"\nresolved = context.resolve_pronouns(transcript2)  # "Place cube on the table"\nresult2 = classifier.classify(resolved)\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,s.jsx)(e.h3,{id:"exercise-1-manipulation-command-parser",children:"Exercise 1: Manipulation Command Parser"}),"\n",(0,s.jsx)(e.p,{children:"Extend the parser to handle manipulation commands:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:['Parse "pick up ',(0,s.jsx)(e.code,{children:"{color}"})," ",(0,s.jsx)(e.code,{children:"{object}"}),'" (e.g., "pick up the red cube")']}),"\n",(0,s.jsxs)(e.li,{children:['Parse "place ',(0,s.jsx)(e.code,{children:"{object}"})," on ",(0,s.jsx)(e.code,{children:"{location}"}),'"']}),"\n",(0,s.jsx)(e.li,{children:"Extract object attributes (color, size: small/large)"}),"\n",(0,s.jsx)(e.li,{children:'Handle compound commands: "Pick up the cube and place it on the shelf"'}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Starter code"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'@dataclass\nclass ManipulationCommand:\n    action: str  # pick_up, place, release\n    object: Optional[str] = None\n    color: Optional[str] = None\n    size: Optional[str] = None\n    location: Optional[str] = None\n\nclass ManipulationParser:\n    def __init__(self):\n        self.nlp = spacy.load("en_core_web_sm")\n\n    def parse(self, transcript: str) -> Optional[ManipulationCommand]:\n        # TODO: Extract intent (pick_up, place, release)\n        # TODO: Extract object name\n        # TODO: Extract color attribute\n        # TODO: Extract location (for "place" commands)\n        pass\n\n# Test cases\ntest_cases = [\n    "Pick up the red cube",\n    "Place the ball on the table",\n    "Grab the small green box",\n    "Put the cup on the counter and release it"\n]\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"exercise-2-confidence-based-fallback",children:"Exercise 2: Confidence-Based Fallback"}),"\n",(0,s.jsx)(e.p,{children:"Implement a system that falls back to LLM (GPT-4) when confidence is low:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"If spaCy confidence < 0.3, use GPT-4 API (from next lesson)"}),"\n",(0,s.jsx)(e.li,{children:"Compare parsing results from both methods"}),"\n",(0,s.jsx)(e.li,{children:"Log which method was used and accuracy"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Starter code"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'class HybridParser:\n    def __init__(self):\n        self.local_parser = IntentClassifier()\n        # TODO: Initialize OpenAI client for GPT-4\n\n    def parse(self, transcript: str) -> dict:\n        # Try local parser first\n        result = self.local_parser.classify(transcript)\n\n        if result.confidence < 0.3:\n            # TODO: Fall back to GPT-4\n            # TODO: Use prompt: "Parse this robot command into JSON: {transcript}"\n            pass\n\n        return result\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"In this lesson, you learned to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"\u2705 Extract intent and entities from voice transcripts using regex and spaCy"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Implement rule-based parsers for structured robotics commands"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Classify intent (navigate, manipulate, perceive) with keyword matching"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Map parsed commands to ROS 2 action messages"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Handle ambiguity with clarification dialogs"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Resolve contextual pronouns using command history"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Rule-based parsers"}),": Fast, deterministic, good for factories/warehouses"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"spaCy NLU"}),": Handles linguistic variation, extracts entities"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Hybrid approach"}),": Use local parsing for speed, LLM for complex cases (next lesson)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Ambiguity"}),": Always validate required parameters before executing"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Context"}),": Track previous commands to resolve pronouns"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,s.jsx)(e.h3,{id:"official-documentation",children:"Official Documentation"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://spacy.io/usage",children:"spaCy Documentation"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://spacy.io/usage/linguistic-features#named-entities",children:"spaCy Entity Recognition"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://docs.ros.org/en/humble/Tutorials/Intermediate/Writing-an-Action-Server-Client/Py.html",children:"ROS 2 Actions"})}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"nlu-training",children:"NLU Training"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://spacy.io/usage/training",children:"spaCy Training Pipelines"})}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://rasa.com/docs/rasa/nlu-training-data/",children:"Rasa NLU"})," - Alternative NLU framework"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"research-papers",children:"Research Papers"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1902.10909",children:"Slot Filling and Intent Detection"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/2004.14354",children:"Contextual Language Understanding for Robotics"})}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"next-lesson",children:"Next Lesson"}),"\n",(0,s.jsxs)(e.p,{children:["In ",(0,s.jsx)(e.strong,{children:"Chapter 12: LLM Planning"}),", you'll learn to:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use GPT-4/Claude for complex command understanding"}),"\n",(0,s.jsx)(e.li,{children:"Engineer prompts for robotics-specific tasks"}),"\n",(0,s.jsx)(e.li,{children:"Generate structured JSON actions from free-form commands"}),"\n",(0,s.jsx)(e.li,{children:"Handle multi-step planning and error recovery"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:["Continue to ",(0,s.jsx)(e.a,{href:"/physical-ai-humanoid-robotics/docs/module-4-vla/ch12-llm-planning/llm-integration",children:"LLM Integration \u2192"})]})]})}function p(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>o});var i=t(6540);const s={},r=i.createContext(s);function a(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);