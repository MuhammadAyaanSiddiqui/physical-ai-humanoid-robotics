"use strict";(globalThis.webpackChunkphysical_ai_course=globalThis.webpackChunkphysical_ai_course||[]).push([[8855],{7402:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-4-vla/ch12-llm-planning/error-handling","title":"Error Handling and Fault Recovery","description":"Learning Objectives","source":"@site/docs/module-4-vla/ch12-llm-planning/error-handling.md","sourceDirName":"module-4-vla/ch12-llm-planning","slug":"/module-4-vla/ch12-llm-planning/error-handling","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch12-llm-planning/error-handling","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/ch12-llm-planning/error-handling.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Action Generation and ROS 2 Conversion","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch12-llm-planning/action-generation"},"next":{"title":"Forward and Inverse Kinematics for Humanoid Robots","permalink":"/physical-ai-humanoid-robotics/docs/module-4-vla/ch13-humanoid-control/forward-inverse-kinematics"}}');var t=r(4848),o=r(8453);const a={},s="Error Handling and Fault Recovery",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Part 1: LLM Error Handling",id:"part-1-llm-error-handling",level:2},{value:"Step 1: JSON Parsing Errors",id:"step-1-json-parsing-errors",level:3},{value:"Step 2: Hallucination Detection",id:"step-2-hallucination-detection",level:3},{value:"Step 3: Rate Limit Handling",id:"step-3-rate-limit-handling",level:3},{value:"Part 2: Execution Error Handling",id:"part-2-execution-error-handling",level:2},{value:"Step 1: Action Failure Recovery",id:"step-1-action-failure-recovery",level:3},{value:"Step 2: Replanning with LLM",id:"step-2-replanning-with-llm",level:3},{value:"Part 3: Clarification Dialogues",id:"part-3-clarification-dialogues",level:2},{value:"Step 1: Ambiguity Detection",id:"step-1-ambiguity-detection",level:3},{value:"Step 2: Interactive Clarification",id:"step-2-interactive-clarification",level:3},{value:"Part 4: Logging and Monitoring",id:"part-4-logging-and-monitoring",level:2},{value:"Step 1: Comprehensive Error Logging",id:"step-1-comprehensive-error-logging",level:3},{value:"Step 2: Error Analytics Dashboard",id:"step-2-error-analytics-dashboard",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Exercise 1: Fallback Chain",id:"exercise-1-fallback-chain",level:3},{value:"Summary",id:"summary",level:2},{value:"Additional Resources",id:"additional-resources",level:2},{value:"Error Handling Patterns",id:"error-handling-patterns",level:3},{value:"Logging Best Practices",id:"logging-best-practices",level:3},{value:"Module 4 Summary",id:"module-4-summary",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"error-handling-and-fault-recovery",children:"Error Handling and Fault Recovery"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Detect and classify LLM and robot execution errors"}),"\n",(0,t.jsx)(e.li,{children:"Implement retry strategies with exponential backoff"}),"\n",(0,t.jsx)(e.li,{children:"Build clarification dialogues for ambiguous commands"}),"\n",(0,t.jsx)(e.li,{children:"Design fallback strategies for failed actions"}),"\n",(0,t.jsx)(e.li,{children:"Create fault-tolerant robot systems"}),"\n",(0,t.jsx)(e.li,{children:"Monitor and log errors for debugging"}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Required Knowledge"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Completion of ",(0,t.jsx)(e.a,{href:"/physical-ai-humanoid-robotics/docs/module-4-vla/ch12-llm-planning/action-generation",children:"Lesson 3: Action Generation"})]}),"\n",(0,t.jsx)(e.li,{children:"Exception handling in Python"}),"\n",(0,t.jsx)(e.li,{children:"ROS 2 action feedback mechanisms"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Estimated Time"}),": 2-3 hours"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"Robust robot systems must handle failures gracefully:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Error Categories"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"LLM Errors"}),": Invalid JSON, hallucinated actions, rate limits"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Validation Errors"}),": Infeasible plans, constraint violations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Execution Errors"}),": Action failures, hardware faults, obstacles"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Ambiguity Errors"}),": Underspecified commands, missing information"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Error Handling Strategy"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Error Detection \u2192 Classification \u2192 Recovery Action \u2192 Logging\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-1-llm-error-handling",children:"Part 1: LLM Error Handling"}),"\n",(0,t.jsx)(e.h3,{id:"step-1-json-parsing-errors",children:"Step 1: JSON Parsing Errors"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport json\nimport re\nfrom typing import Optional\n\nclass LLMOutputParser:\n    """Robust parser for LLM outputs"""\n\n    def parse_json(self, llm_output: str, max_retries: int = 3) -> Optional[dict]:\n        """Parse JSON with fallback strategies"""\n\n        # Strategy 1: Direct JSON parsing\n        try:\n            return json.loads(llm_output)\n        except json.JSONDecodeError:\n            pass\n\n        # Strategy 2: Extract JSON from markdown code blocks\n        json_match = re.search(r\'```(?:json)?\\s*(\\{.*?\\})\\s*```\', llm_output, re.DOTALL)\n        if json_match:\n            try:\n                return json.loads(json_match.group(1))\n            except json.JSONDecodeError:\n                pass\n\n        # Strategy 3: Find first { } pair\n        start = llm_output.find(\'{\')\n        end = llm_output.rfind(\'}\')\n        if start != -1 and end != -1 and end > start:\n            try:\n                return json.loads(llm_output[start:end+1])\n            except json.JSONDecodeError:\n                pass\n\n        # Strategy 4: Fix common JSON issues\n        fixed = self.fix_common_json_errors(llm_output)\n        if fixed:\n            try:\n                return json.loads(fixed)\n            except json.JSONDecodeError:\n                pass\n\n        # All strategies failed\n        return None\n\n    def fix_common_json_errors(self, text: str) -> Optional[str]:\n        """Fix common JSON formatting errors"""\n\n        # Remove trailing commas\n        text = re.sub(r\',(\\s*[}\\]])\', r\'\\1\', text)\n\n        # Fix single quotes to double quotes\n        text = text.replace("\'", \'"\')\n\n        # Fix unquoted keys (simple cases)\n        text = re.sub(r\'(\\{|,)\\s*([a-zA-Z_][a-zA-Z0-9_]*)\\s*:\', r\'\\1 "\\2":\', text)\n\n        return text\n\n# Usage\nparser = LLMOutputParser()\n\n# Malformed JSON from LLM\nbad_output = """\nHere\'s the plan:\n{\n  plan: [\n    {"action": "move", "distance": 3.0,}  // trailing comma\n  ]\n}\n"""\n\nresult = parser.parse_json(bad_output)\nif result:\n    print("\u2705 Successfully parsed:", result)\nelse:\n    print("\u274c Failed to parse JSON")\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h3,{id:"step-2-hallucination-detection",children:"Step 2: Hallucination Detection"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class HallucinationDetector:\n    \"\"\"Detect when LLM invents non-existent actions or capabilities\"\"\"\n\n    def __init__(self):\n        # Define valid action set\n        self.valid_actions = {\n            'navigate', 'pick', 'place', 'scan', 'wait'\n        }\n\n        # Define known entities\n        self.known_objects = {\n            'cup', 'plate', 'cube', 'ball', 'book', 'box'\n        }\n\n        self.known_locations = {\n            'kitchen', 'bedroom', 'living_room', 'table', 'shelf'\n        }\n\n    def detect_hallucinations(self, plan: dict) -> list:\n        \"\"\"Detect hallucinated actions or entities\"\"\"\n        hallucinations = []\n\n        for i, action in enumerate(plan.get('plan', [])):\n            # Check action type\n            action_type = action.get('action', '').lower()\n            if action_type not in self.valid_actions:\n                hallucinations.append({\n                    'type': 'invalid_action',\n                    'action_index': i,\n                    'value': action_type,\n                    'message': f\"Action '{action_type}' does not exist\"\n                })\n\n            # Check object names\n            if 'object' in action:\n                obj = action['object'].lower()\n                if obj not in self.known_objects:\n                    hallucinations.append({\n                        'type': 'unknown_object',\n                        'action_index': i,\n                        'value': obj,\n                        'message': f\"Object '{obj}' not in environment\"\n                    })\n\n            # Check locations\n            if 'location' in action:\n                loc = action['location'].lower()\n                if loc not in self.known_locations:\n                    hallucinations.append({\n                        'type': 'unknown_location',\n                        'action_index': i,\n                        'value': loc,\n                        'message': f\"Location '{loc}' not found\"\n                    })\n\n        return hallucinations\n\n# Usage\ndetector = HallucinationDetector()\n\n# Plan with hallucinated action\nbad_plan = {\n    'plan': [\n        {'action': 'fly', 'height': 10.0},  # Robot can't fly!\n        {'action': 'pick', 'object': 'dragon'}  # Dragon doesn't exist!\n    ]\n}\n\nhallucinations = detector.detect_hallucinations(bad_plan)\nfor h in hallucinations:\n    print(f\"\u274c {h['type']}: {h['message']}\")\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h3,{id:"step-3-rate-limit-handling",children:"Step 3: Rate Limit Handling"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import time\nfrom openai import OpenAI, RateLimitError\nfrom collections import deque\n\nclass RateLimitedLLMClient:\n    """LLM client with automatic rate limiting"""\n\n    def __init__(self, requests_per_minute: int = 50):\n        self.client = OpenAI()\n        self.rpm = requests_per_minute\n        self.request_times = deque()\n\n    def call_llm(self, messages: list, max_retries: int = 5) -> str:\n        """Call LLM with rate limiting and retries"""\n\n        for attempt in range(max_retries):\n            try:\n                # Wait if rate limit would be exceeded\n                self._wait_if_rate_limited()\n\n                # Make request\n                response = self.client.chat.completions.create(\n                    model="gpt-4o-mini",\n                    messages=messages,\n                    temperature=0.0\n                )\n\n                # Log request time\n                self.request_times.append(time.time())\n\n                return response.choices[0].message.content\n\n            except RateLimitError:\n                wait_time = 2 ** attempt  # Exponential backoff\n                print(f"\u26a0\ufe0f Rate limit hit. Waiting {wait_time}s... (attempt {attempt+1}/{max_retries})")\n                time.sleep(wait_time)\n\n        raise Exception("Max retries exceeded due to rate limiting")\n\n    def _wait_if_rate_limited(self):\n        """Wait if we\'re about to exceed rate limit"""\n        now = time.time()\n\n        # Remove requests older than 1 minute\n        while self.request_times and self.request_times[0] < now - 60:\n            self.request_times.popleft()\n\n        # Check if at limit\n        if len(self.request_times) >= self.rpm:\n            # Wait until oldest request is 60s old\n            sleep_time = 60 - (now - self.request_times[0])\n            if sleep_time > 0:\n                print(f"\u23f3 Rate limit approaching. Waiting {sleep_time:.1f}s...")\n                time.sleep(sleep_time)\n\n# Usage\nclient = RateLimitedLLMClient(requests_per_minute=50)\n\n# Make 100 requests - will automatically throttle\nfor i in range(100):\n    response = client.call_llm([\n        {"role": "user", "content": f"Plan {i}"}\n    ])\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-2-execution-error-handling",children:"Part 2: Execution Error Handling"}),"\n",(0,t.jsx)(e.h3,{id:"step-1-action-failure-recovery",children:"Step 1: Action Failure Recovery"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"from enum import Enum\n\nclass FailureReason(Enum):\n    OBSTACLE = \"obstacle_detected\"\n    OBJECT_NOT_FOUND = \"object_not_found\"\n    GRASP_FAILED = \"grasp_failed\"\n    TIMEOUT = \"timeout\"\n    HARDWARE_ERROR = \"hardware_error\"\n    UNKNOWN = \"unknown\"\n\nclass ActionRecoveryStrategy:\n    \"\"\"Determine recovery action based on failure reason\"\"\"\n\n    def get_recovery_plan(self, failed_action: dict, reason: FailureReason) -> list:\n        \"\"\"Generate recovery plan based on failure type\"\"\"\n\n        if reason == FailureReason.OBSTACLE:\n            return [\n                {'action': 'navigate', 'x': -0.5, 'y': 0.0},  # Back up\n                {'action': 'scan'},  # Re-scan environment\n                failed_action  # Retry original action\n            ]\n\n        elif reason == FailureReason.OBJECT_NOT_FOUND:\n            return [\n                {'action': 'scan', 'target': failed_action.get('object')},\n                {'action': 'wait', 'duration': 1.0},\n                failed_action  # Retry after scanning\n            ]\n\n        elif reason == FailureReason.GRASP_FAILED:\n            return [\n                {'action': 'release'},  # Open gripper\n                {'action': 'wait', 'duration': 0.5},\n                failed_action  # Retry grasp\n            ]\n\n        elif reason == FailureReason.TIMEOUT:\n            # Simplify action (e.g., break into smaller steps)\n            return self.simplify_action(failed_action)\n\n        else:\n            # Unknown error - ask for help\n            return [\n                {'action': 'wait', 'duration': 1.0},\n                {'action': 'request_help', 'reason': str(reason)}\n            ]\n\n    def simplify_action(self, action: dict) -> list:\n        \"\"\"Break complex action into simpler steps\"\"\"\n\n        if action['action'] == 'navigate' and 'distance' in action:\n            # Break long movement into smaller steps\n            distance = action['distance']\n            if distance > 2.0:\n                return [\n                    {'action': 'navigate', 'direction': action['direction'], 'distance': 2.0},\n                    {'action': 'navigate', 'direction': action['direction'], 'distance': distance - 2.0}\n                ]\n\n        return [action]  # Can't simplify, return as-is\n\n# Usage\nrecovery = ActionRecoveryStrategy()\n\nfailed_action = {'action': 'pick', 'object': 'cup'}\nreason = FailureReason.OBJECT_NOT_FOUND\n\nrecovery_plan = recovery.get_recovery_plan(failed_action, reason)\nprint(f\"Recovery plan: {recovery_plan}\")\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h3,{id:"step-2-replanning-with-llm",children:"Step 2: Replanning with LLM"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class AdaptivePlanner:\n    """Use LLM to replan when execution fails"""\n\n    def __init__(self, llm_client):\n        self.client = llm_client\n\n    def replan_after_failure(\n        self,\n        original_command: str,\n        failed_action: dict,\n        failure_reason: str,\n        current_state: dict\n    ) -> dict:\n        """Ask LLM to generate alternative plan"""\n\n        replan_prompt = f"""\nORIGINAL COMMAND: {original_command}\n\nEXECUTION FAILURE:\n- Failed action: {failed_action}\n- Reason: {failure_reason}\n\nCURRENT STATE:\n- Location: {current_state.get(\'location\')}\n- Holding: {current_state.get(\'holding\') or \'nothing\'}\n- Visible objects: {current_state.get(\'visible_objects\', [])}\n\nGenerate an alternative plan to achieve the original goal, avoiding the failed action.\nConsider:\n1. Can we achieve the goal differently?\n2. Do we need to gather more information first?\n3. Is the goal still achievable given the failure?\n\nOutput JSON plan or {{" error": "goal_not_achievable", "reason": "..." }} if impossible.\n"""\n\n        response = self.client.call_llm([\n            {"role": "system", "content": "You are a robot replanning assistant."},\n            {"role": "user", "content": replan_prompt}\n        ])\n\n        return json.loads(response)\n\n# Usage\nplanner = AdaptivePlanner(client)\n\nalternative_plan = planner.replan_after_failure(\n    original_command="Pick up the red cup",\n    failed_action={\'action\': \'pick\', \'object\': \'cup\'},\n    failure_reason="Cup is too heavy (6kg > 5kg limit)",\n    current_state={\'location\': \'kitchen\', \'holding\': None, \'visible_objects\': [\'cup\', \'plate\']}\n)\n\nprint(json.dumps(alternative_plan, indent=2))\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-3-clarification-dialogues",children:"Part 3: Clarification Dialogues"}),"\n",(0,t.jsx)(e.h3,{id:"step-1-ambiguity-detection",children:"Step 1: Ambiguity Detection"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class AmbiguityDetector:\n    \"\"\"Detect when commands are underspecified\"\"\"\n\n    def detect_ambiguity(self, command: str, environment: dict) -> Optional[str]:\n        \"\"\"Return clarification question if command is ambiguous\"\"\"\n\n        # Check for vague references\n        if 'it' in command.lower():\n            return \"What does 'it' refer to?\"\n\n        if 'there' in command.lower():\n            return \"Where is 'there'?\"\n\n        # Check for unspecified objects\n        if 'pick' in command.lower() or 'grab' in command.lower():\n            # Check if object is specified\n            objects_in_view = environment.get('visible_objects', [])\n\n            # If multiple objects and none specified\n            if len(objects_in_view) > 1 and not any(obj in command.lower() for obj in objects_in_view):\n                return f\"Which object? I see: {', '.join(objects_in_view)}\"\n\n        # Check for unspecified colors when multiple same objects\n        object_counts = self._count_objects_by_type(environment.get('visible_objects', []))\n        for obj_type, count in object_counts.items():\n            if count > 1 and obj_type in command.lower():\n                return f\"Which {obj_type}? I see {count} of them.\"\n\n        return None  # No ambiguity detected\n\n    def _count_objects_by_type(self, objects: list) -> dict:\n        \"\"\"Count objects by type\"\"\"\n        counts = {}\n        for obj in objects:\n            obj_type = obj.split('_')[0]  # 'red_cup' \u2192 'cup'\n            counts[obj_type] = counts.get(obj_type, 0) + 1\n        return counts\n\n# Usage\ndetector = AmbiguityDetector()\n\nenv = {'visible_objects': ['red_cup', 'blue_cup', 'plate']}\n\ncommand = \"Pick up the cup\"\nclarification = detector.detect_ambiguity(command, env)\n\nif clarification:\n    print(f\"\ud83e\udd14 {clarification}\")\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h3,{id:"step-2-interactive-clarification",children:"Step 2: Interactive Clarification"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\n\nclass ClarificationNode(Node):\n    """ROS 2 node for handling clarifications"""\n\n    def __init__(self):\n        super().__init__(\'clarification_node\')\n\n        # Publishers\n        self.question_pub = self.create_publisher(\n            String, \'voice/clarification_question\', 10\n        )\n\n        # Subscribers\n        self.response_sub = self.create_subscription(\n            String, \'voice/clarification_response\', self.response_callback, 10\n        )\n\n        self.pending_command = None\n        self.clarification_context = {}\n\n    def ask_clarification(self, question: str, original_command: str, context: dict):\n        """Ask user for clarification"""\n        self.pending_command = original_command\n        self.clarification_context = context\n\n        msg = String()\n        msg.data = question\n        self.question_pub.publish(msg)\n\n        self.get_logger().info(f"\ud83e\udd14 Asking: {question}")\n\n    def response_callback(self, msg: String):\n        """Handle clarification response"""\n        response = msg.data\n\n        if not self.pending_command:\n            return\n\n        # Incorporate clarification into original command\n        enhanced_command = f"{self.pending_command}. Specifically: {response}"\n\n        self.get_logger().info(f"\u2713 Clarified: {enhanced_command}")\n\n        # Re-process enhanced command\n        # TODO: Send to LLM planning service\n\n        # Clear pending state\n        self.pending_command = None\n        self.clarification_context = {}\n\n# Usage\n# User says: "Pick up the cup"\n# System detects ambiguity (2 cups visible)\n# System asks: "Which cup? I see: red_cup, blue_cup"\n# User responds: "The red one"\n# System processes: "Pick up the cup. Specifically: The red one"\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-4-logging-and-monitoring",children:"Part 4: Logging and Monitoring"}),"\n",(0,t.jsx)(e.h3,{id:"step-1-comprehensive-error-logging",children:"Step 1: Comprehensive Error Logging"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import logging\nimport json\nfrom datetime import datetime\n\nclass RobotErrorLogger:\n    \"\"\"Structured logging for robot errors\"\"\"\n\n    def __init__(self, log_file: str = \"robot_errors.jsonl\"):\n        self.log_file = log_file\n\n        # Configure Python logging\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s [%(levelname)s] %(message)s'\n        )\n        self.logger = logging.getLogger(__name__)\n\n    def log_llm_error(self, command: str, error: Exception, llm_output: str = \"\"):\n        \"\"\"Log LLM-related errors\"\"\"\n        error_record = {\n            'timestamp': datetime.now().isoformat(),\n            'error_type': 'llm_error',\n            'command': command,\n            'exception': str(error),\n            'llm_output': llm_output[:500]  # Truncate long outputs\n        }\n\n        self._write_log(error_record)\n\n    def log_execution_error(\n        self,\n        action: dict,\n        failure_reason: str,\n        recovery_attempted: bool = False\n    ):\n        \"\"\"Log action execution errors\"\"\"\n        error_record = {\n            'timestamp': datetime.now().isoformat(),\n            'error_type': 'execution_error',\n            'action': action,\n            'failure_reason': failure_reason,\n            'recovery_attempted': recovery_attempted\n        }\n\n        self._write_log(error_record)\n\n    def log_clarification_request(self, command: str, question: str, response: str = \"\"):\n        \"\"\"Log clarification interactions\"\"\"\n        error_record = {\n            'timestamp': datetime.now().isoformat(),\n            'error_type': 'clarification_needed',\n            'command': command,\n            'question': question,\n            'user_response': response\n        }\n\n        self._write_log(error_record)\n\n    def _write_log(self, record: dict):\n        \"\"\"Write JSON record to log file\"\"\"\n        with open(self.log_file, 'a') as f:\n            f.write(json.dumps(record) + '\\n')\n\n        self.logger.info(json.dumps(record))\n\n# Usage\nerror_logger = RobotErrorLogger()\n\ntry:\n    # Attempt LLM call\n    response = client.call_llm(messages)\nexcept Exception as e:\n    error_logger.log_llm_error(\n        command=\"Pick up the cup\",\n        error=e,\n        llm_output=\"\"\n    )\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h3,{id:"step-2-error-analytics-dashboard",children:"Step 2: Error Analytics Dashboard"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class ErrorAnalytics:\n    \"\"\"Analyze error logs for patterns\"\"\"\n\n    def __init__(self, log_file: str = \"robot_errors.jsonl\"):\n        self.log_file = log_file\n\n    def get_error_summary(self, hours: int = 24) -> dict:\n        \"\"\"Get error statistics for last N hours\"\"\"\n        import json\n        from datetime import datetime, timedelta\n\n        cutoff_time = datetime.now() - timedelta(hours=hours)\n\n        errors = {\n            'llm_error': 0,\n            'execution_error': 0,\n            'clarification_needed': 0\n        }\n\n        failure_reasons = {}\n\n        with open(self.log_file, 'r') as f:\n            for line in f:\n                record = json.loads(line)\n                timestamp = datetime.fromisoformat(record['timestamp'])\n\n                if timestamp >= cutoff_time:\n                    error_type = record['error_type']\n                    errors[error_type] = errors.get(error_type, 0) + 1\n\n                    if error_type == 'execution_error':\n                        reason = record.get('failure_reason', 'unknown')\n                        failure_reasons[reason] = failure_reasons.get(reason, 0) + 1\n\n        return {\n            'period_hours': hours,\n            'total_errors': sum(errors.values()),\n            'by_type': errors,\n            'top_failure_reasons': sorted(\n                failure_reasons.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:5]\n        }\n\n# Usage\nanalytics = ErrorAnalytics()\nsummary = analytics.get_error_summary(hours=24)\n\nprint(f\"Last 24 hours: {summary['total_errors']} errors\")\nprint(f\"  LLM errors: {summary['by_type']['llm_error']}\")\nprint(f\"  Execution errors: {summary['by_type']['execution_error']}\")\nprint(f\"  Clarifications: {summary['by_type']['clarification_needed']}\")\nprint(\"\\nTop failure reasons:\")\nfor reason, count in summary['top_failure_reasons']:\n    print(f\"  {reason}: {count}\")\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,t.jsx)(e.h3,{id:"exercise-1-fallback-chain",children:"Exercise 1: Fallback Chain"}),"\n",(0,t.jsx)(e.p,{children:"Implement a multi-level fallback strategy:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Level 1: Retry action (3 attempts)"}),"\n",(0,t.jsx)(e.li,{children:"Level 2: Try alternative action from recovery strategy"}),"\n",(0,t.jsx)(e.li,{children:"Level 3: Replan with LLM"}),"\n",(0,t.jsx)(e.li,{children:"Level 4: Ask user for help"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Starter code"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class FallbackChain:\n    def execute_with_fallbacks(self, action: dict) -> bool:\n        # Level 1: Retry\n        for i in range(3):\n            if self.try_execute(action):\n                return True\n            time.sleep(1)\n\n        # Level 2: Recovery strategy\n        # TODO: Get recovery plan and try executing\n\n        # Level 3: Replan with LLM\n        # TODO: Call LLM replanner\n\n        # Level 4: Ask user\n        # TODO: Publish help request\n\n        return False\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"In this lesson, you learned to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u2705 Handle LLM errors (JSON parsing, hallucinations, rate limits)"}),"\n",(0,t.jsx)(e.li,{children:"\u2705 Implement execution error recovery with retries and replanning"}),"\n",(0,t.jsx)(e.li,{children:"\u2705 Detect and resolve ambiguous commands through clarification"}),"\n",(0,t.jsx)(e.li,{children:"\u2705 Build comprehensive error logging and analytics"}),"\n",(0,t.jsx)(e.li,{children:"\u2705 Create fault-tolerant robot systems with fallback strategies"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Always validate"}),": Check LLM outputs before execution"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Graceful degradation"}),": Implement fallback chains"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Learn from failures"}),": Log and analyze error patterns"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Involve humans"}),": Ask for clarification when uncertain"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,t.jsx)(e.h3,{id:"error-handling-patterns",children:"Error Handling Patterns"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://docs.microsoft.com/en-us/azure/architecture/patterns/retry",children:"Retry Pattern"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://martinfowler.com/bliki/CircuitBreaker.html",children:"Circuit Breaker Pattern"})}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"logging-best-practices",children:"Logging Best Practices"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://www.loggly.com/ultimate-guide/python-logging-basics/",children:"Structured Logging"})}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.a,{href:"https://opentelemetry.io/",children:"OpenTelemetry"})," - Observability framework"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"module-4-summary",children:"Module 4 Summary"}),"\n",(0,t.jsx)(e.p,{children:"Congratulations! You've completed Chapter 12: Cognitive Planning. You can now:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Integrate GPT-4/Claude for robot planning"}),"\n",(0,t.jsx)(e.li,{children:"Engineer effective prompts for robotics"}),"\n",(0,t.jsx)(e.li,{children:"Generate and execute ROS 2 actions from LLM outputs"}),"\n",(0,t.jsx)(e.li,{children:"Handle errors and implement fault recovery"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Next"}),": Continue to Chapter 13 for humanoid kinematics and locomotion control."]}),"\n",(0,t.jsxs)(e.p,{children:["Continue to ",(0,t.jsx)(e.a,{href:"/physical-ai-humanoid-robotics/docs/module-4-vla/ch13-humanoid-control/forward-inverse-kinematics",children:"Chapter 13: Humanoid Control \u2192"})]})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>a,x:()=>s});var i=r(6540);const t={},o=i.createContext(t);function a(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:a(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);