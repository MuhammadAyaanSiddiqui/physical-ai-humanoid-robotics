"use strict";(globalThis.webpackChunkphysical_ai_course=globalThis.webpackChunkphysical_ai_course||[]).push([[832],{8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>t});var i=s(6540);const r={},a=i.createContext(r);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(a.Provider,{value:n},e.children)}},9132:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3-isaac/ch8-perception/vslam","title":"Visual SLAM (VSLAM)","description":"Overview","source":"@site/docs/module-3-isaac/ch8-perception/vslam.md","sourceDirName":"module-3-isaac/ch8-perception","slug":"/module-3-isaac/ch8-perception/vslam","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/ch8-perception/vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-isaac/ch8-perception/vslam.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Domain Randomization","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/ch7-isaac-sim/domain-randomization"},"next":{"title":"Object Detection with DNN Inference","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/ch8-perception/object-detection"}}');var r=s(4848),a=s(8453);const l={},t="Visual SLAM (VSLAM)",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Part 1: VSLAM Fundamentals",id:"part-1-vslam-fundamentals",level:2},{value:"What is SLAM?",id:"what-is-slam",level:3},{value:"Visual SLAM vs. LiDAR SLAM",id:"visual-slam-vs-lidar-slam",level:3},{value:"How Visual SLAM Works",id:"how-visual-slam-works",level:3},{value:"Part 2: Isaac ROS VSLAM Setup",id:"part-2-isaac-ros-vslam-setup",level:2},{value:"Step 1: Install Isaac ROS VSLAM",id:"step-1-install-isaac-ros-vslam",level:3},{value:"Step 2: Verify Installation",id:"step-2-verify-installation",level:3},{value:"Part 3: Running VSLAM in Isaac Sim",id:"part-3-running-vslam-in-isaac-sim",level:2},{value:"Step 1: Create a Test Scene in Isaac Sim",id:"step-1-create-a-test-scene-in-isaac-sim",level:3},{value:"Step 2: Add a Robot with Stereo Camera",id:"step-2-add-a-robot-with-stereo-camera",level:3},{value:"Step 3: Configure ROS 2 Bridge",id:"step-3-configure-ros-2-bridge",level:3},{value:"Step 4: Launch Isaac ROS VSLAM Node",id:"step-4-launch-isaac-ros-vslam-node",level:3},{value:"Step 5: Drive the Robot in Isaac Sim",id:"step-5-drive-the-robot-in-isaac-sim",level:3},{value:"Part 4: Visualizing VSLAM in RViz",id:"part-4-visualizing-vslam-in-rviz",level:2},{value:"Step 1: Launch RViz",id:"step-1-launch-rviz",level:3},{value:"Step 2: Add VSLAM Visualizations",id:"step-2-add-vslam-visualizations",level:3},{value:"Step 3: Observe VSLAM Performance",id:"step-3-observe-vslam-performance",level:3},{value:"Part 5: Understanding VSLAM Output",id:"part-5-understanding-vslam-output",level:2},{value:"Key ROS 2 Topics",id:"key-ros-2-topics",level:3},{value:"Inspecting Odometry",id:"inspecting-odometry",level:3},{value:"Inspecting Map Quality",id:"inspecting-map-quality",level:3},{value:"Part 6: Evaluating SLAM Performance",id:"part-6-evaluating-slam-performance",level:2},{value:"Metric 1: Trajectory Accuracy (Drift)",id:"metric-1-trajectory-accuracy-drift",level:3},{value:"Metric 2: Loop Closure Detection",id:"metric-2-loop-closure-detection",level:3},{value:"Metric 3: Tracking Loss",id:"metric-3-tracking-loss",level:3},{value:"Part 7: Advanced VSLAM Configuration",id:"part-7-advanced-vslam-configuration",level:2},{value:"Tuning Parameters",id:"tuning-parameters",level:3},{value:"Using IMU Fusion",id:"using-imu-fusion",level:3},{value:"Part 8: Exporting Maps for Navigation",id:"part-8-exporting-maps-for-navigation",level:2},{value:"Step 1: Save Map",id:"step-1-save-map",level:3},{value:"Step 2: Convert to Occupancy Grid (for Nav2)",id:"step-2-convert-to-occupancy-grid-for-nav2",level:3},{value:"Step 3: Use Map with Nav2",id:"step-3-use-map-with-nav2",level:3},{value:"Part 9: Common VSLAM Issues &amp; Solutions",id:"part-9-common-vslam-issues--solutions",level:2},{value:"Issue 1: VSLAM Fails to Initialize",id:"issue-1-vslam-fails-to-initialize",level:3},{value:"Issue 2: High Drift (Map Warps Over Time)",id:"issue-2-high-drift-map-warps-over-time",level:3},{value:"Issue 3: Tracking Lost in Textureless Areas",id:"issue-3-tracking-lost-in-textureless-areas",level:3},{value:"Part 10: Hands-On Exercise",id:"part-10-hands-on-exercise",level:2},{value:"Exercise: Map a Multi-Room Environment",id:"exercise-map-a-multi-room-environment",level:3},{value:"Requirements",id:"requirements",level:4},{value:"Deliverables",id:"deliverables",level:4},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"visual-slam-vslam",children:"Visual SLAM (VSLAM)"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Visual SLAM (Simultaneous Localization and Mapping)"})," enables robots to build maps of unknown environments while simultaneously tracking their position within those maps, using only camera input. This is a foundational capability for autonomous navigation, allowing robots to operate without GPS or pre-built maps."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What You'll Learn"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Understand VSLAM principles and algorithms (ORB-SLAM, RTAB-Map)"}),"\n",(0,r.jsx)(n.li,{children:"Configure Isaac ROS VSLAM nodes"}),"\n",(0,r.jsx)(n.li,{children:"Run visual SLAM in Isaac Sim with camera sensors"}),"\n",(0,r.jsx)(n.li,{children:"Evaluate map quality and localization accuracy"}),"\n",(0,r.jsx)(n.li,{children:"Integrate VSLAM with ROS 2 navigation stack"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Prerequisites"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Completed Chapter 7 (Isaac Sim fundamentals)"}),"\n",(0,r.jsx)(n.li,{children:"ROS 2 fundamentals from Module 1"}),"\n",(0,r.jsx)(n.li,{children:"Understanding of coordinate frames and transformations"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Estimated Time"}),": 3-4 hours"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Explain how visual SLAM works (feature extraction, tracking, mapping)"}),"\n",(0,r.jsx)(n.li,{children:"Install and configure Isaac ROS VSLAM"}),"\n",(0,r.jsx)(n.li,{children:"Run VSLAM in Isaac Sim with simulated cameras"}),"\n",(0,r.jsx)(n.li,{children:"Visualize maps and trajectories in RViz"}),"\n",(0,r.jsx)(n.li,{children:"Evaluate SLAM performance (drift, loop closure)"}),"\n",(0,r.jsx)(n.li,{children:"Export maps for autonomous navigation"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-1-vslam-fundamentals",children:"Part 1: VSLAM Fundamentals"}),"\n",(0,r.jsx)(n.h3,{id:"what-is-slam",children:"What is SLAM?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"})," solves two interdependent problems:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Localization"}),': "Where am I?" - Estimate robot pose (position + orientation)']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mapping"}),': "What does the environment look like?" - Build a map of surroundings']}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"The Challenge"}),": You need a map to localize, but you need to know your location to build a map. SLAM solves both simultaneously."]}),"\n",(0,r.jsx)(n.h3,{id:"visual-slam-vs-lidar-slam",children:"Visual SLAM vs. LiDAR SLAM"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspect"}),(0,r.jsx)(n.th,{children:"Visual SLAM"}),(0,r.jsx)(n.th,{children:"LiDAR SLAM"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Sensor"})}),(0,r.jsx)(n.td,{children:"Camera (RGB or stereo)"}),(0,r.jsx)(n.td,{children:"Laser rangefinder"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Data Type"})}),(0,r.jsx)(n.td,{children:"Images"}),(0,r.jsx)(n.td,{children:"Point clouds"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Cost"})}),(0,r.jsx)(n.td,{children:"Low ($50-200 for camera)"}),(0,r.jsx)(n.td,{children:"High ($500-$10,000 for LiDAR)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Indoor Performance"})}),(0,r.jsx)(n.td,{children:"Excellent (texture-rich)"}),(0,r.jsx)(n.td,{children:"Good (geometry-based)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Outdoor Performance"})}),(0,r.jsx)(n.td,{children:"Good (depends on lighting)"}),(0,r.jsx)(n.td,{children:"Excellent (sunlight invariant)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Compute"})}),(0,r.jsx)(n.td,{children:"High (image processing)"}),(0,r.jsx)(n.td,{children:"Medium"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"For this course"}),": We focus on ",(0,r.jsx)(n.strong,{children:"visual SLAM"})," due to lower cost and Isaac ROS GPU acceleration."]}),"\n",(0,r.jsx)(n.h3,{id:"how-visual-slam-works",children:"How Visual SLAM Works"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Pipeline"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Camera Image \u2192 Feature Detection \u2192 Feature Tracking \u2192 Pose Estimation \u2192 Map Update \u2192 Loop Closure\n     \u2502              \u2502                    \u2502                  \u2502               \u2502             \u2502\n   640x480        Keypoints          Match keypoints     Calculate       Add new      Detect\n    RGB          (ORB, SIFT)         across frames       camera pose    landmarks   revisited areas\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Concepts"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Features/Keypoints"}),": Distinctive image points (corners, edges) that can be reliably detected"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Descriptors"}),": Mathematical representations of features for matching across frames"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pose Estimation"}),": Calculate camera movement from matched features (using geometry)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Bundle Adjustment"}),": Optimize camera poses and 3D landmark positions jointly"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loop Closure"}),": Detect when robot returns to a previously visited location (corrects drift)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-2-isaac-ros-vslam-setup",children:"Part 2: Isaac ROS VSLAM Setup"}),"\n",(0,r.jsx)(n.p,{children:"Isaac ROS provides GPU-accelerated VSLAM optimized for NVIDIA hardware."}),"\n",(0,r.jsx)(n.h3,{id:"step-1-install-isaac-ros-vslam",children:"Step 1: Install Isaac ROS VSLAM"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Navigate to ROS 2 workspace\ncd ~/ros2_ws/src\n\n# Clone Isaac ROS VSLAM repository\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\n\n# Install dependencies\ncd ~/ros2_ws\nrosdep install --from-paths src --ignore-src -r -y\n\n# Build the package\ncolcon build --packages-select isaac_ros_visual_slam\n\n# Source workspace\nsource install/setup.bash\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Installation Time"}),": 5-10 minutes"]}),"\n",(0,r.jsx)(n.h3,{id:"step-2-verify-installation",children:"Step 2: Verify Installation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check if VSLAM node is available\nros2 pkg list | grep isaac_ros_visual_slam\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected Output"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"isaac_ros_visual_slam\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-3-running-vslam-in-isaac-sim",children:"Part 3: Running VSLAM in Isaac Sim"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-create-a-test-scene-in-isaac-sim",children:"Step 1: Create a Test Scene in Isaac Sim"}),"\n",(0,r.jsx)(n.p,{children:"We need a textured environment for VSLAM (features need visual variation):"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Launch Isaac Sim"}),"\n",(0,r.jsxs)(n.li,{children:["Load a pre-built environment:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"File"})," > ",(0,r.jsx)(n.strong,{children:"Open"})]}),"\n",(0,r.jsxs)(n.li,{children:["Navigate to: ",(0,r.jsx)(n.code,{children:"omniverse://localhost/NVIDIA/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/warehouse.usd"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This warehouse has good visual texture (shelves, boxes, markings) for VSLAM."}),"\n",(0,r.jsx)(n.h3,{id:"step-2-add-a-robot-with-stereo-camera",children:"Step 2: Add a Robot with Stereo Camera"}),"\n",(0,r.jsx)(n.p,{children:"We'll use the Carter robot (NVIDIA's reference mobile robot):"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Utils"})," > ",(0,r.jsx)(n.strong,{children:"Assets"})," > ",(0,r.jsx)(n.strong,{children:"Robots"})," > ",(0,r.jsx)(n.strong,{children:"Carter"})]}),"\n",(0,r.jsxs)(n.li,{children:["Drag Carter into the scene at position ",(0,r.jsx)(n.code,{children:"(0, 0, 0)"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Carter comes pre-configured with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Stereo camera pair (left/right)"}),"\n",(0,r.jsx)(n.li,{children:"IMU"}),"\n",(0,r.jsx)(n.li,{children:"Wheel odometry"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-3-configure-ros-2-bridge",children:"Step 3: Configure ROS 2 Bridge"}),"\n",(0,r.jsx)(n.p,{children:"To get camera data from Isaac Sim into ROS 2:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac Utils"})," > ",(0,r.jsx)(n.strong,{children:"ROS 2 Bridge"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Enable the following topics:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/front_stereo_camera/left/image_raw"})," (left camera RGB)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/front_stereo_camera/right/image_raw"})," (right camera RGB)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/front_stereo_camera/left/camera_info"})," (camera calibration)"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"/front_stereo_camera/right/camera_info"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Click ",(0,r.jsx)(n.strong,{children:"Enable ROS 2 Bridge"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-4-launch-isaac-ros-vslam-node",children:"Step 4: Launch Isaac ROS VSLAM Node"}),"\n",(0,r.jsx)(n.p,{children:"In a terminal:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Source ROS 2 workspace\nsource ~/ros2_ws/install/setup.bash\n\n# Launch VSLAM node\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected Output"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[isaac_ros_visual_slam]: Visual SLAM node started\n[isaac_ros_visual_slam]: Waiting for stereo camera images...\n[isaac_ros_visual_slam]: Received first image pair\n[isaac_ros_visual_slam]: Initialization complete\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-5-drive-the-robot-in-isaac-sim",children:"Step 5: Drive the Robot in Isaac Sim"}),"\n",(0,r.jsx)(n.p,{children:"VSLAM needs camera motion to build a map. Move Carter around:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Option 1: Keyboard Teleop"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# In a new terminal\nros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args --remap cmd_vel:=/cmd_vel\n"})}),"\n",(0,r.jsx)(n.p,{children:"Use keyboard controls:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"i"})," = Forward"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:","})," = Backward"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"j"})," = Turn left"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"l"})," = Turn right"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Option 2: Scripted Path (Python)"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom geometry_msgs.msg import Twist\n\n# Initialize ROS 2 node\nrclpy.init()\nnode = rclpy.create_node('vslam_test_driver')\npub = node.create_publisher(Twist, '/cmd_vel', 10)\n\n# Drive in a square pattern\ncommands = [\n    (0.5, 0.0, 3.0),  # Forward 3 seconds\n    (0.0, 0.5, 3.14), # Turn 90\xb0 (3.14 seconds at 0.5 rad/s)\n    (0.5, 0.0, 3.0),  # Forward\n    (0.0, 0.5, 3.14), # Turn 90\xb0\n    # ... repeat\n]\n\nfor linear, angular, duration in commands:\n    msg = Twist()\n    msg.linear.x = linear\n    msg.angular.z = angular\n    pub.publish(msg)\n    time.sleep(duration)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-4-visualizing-vslam-in-rviz",children:"Part 4: Visualizing VSLAM in RViz"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-launch-rviz",children:"Step 1: Launch RViz"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rviz2\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-add-vslam-visualizations",children:"Step 2: Add VSLAM Visualizations"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add"})," > ",(0,r.jsx)(n.strong,{children:"TF"})," (coordinate frame transformations)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Shows robot pose and camera frames"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add"})," > ",(0,r.jsx)(n.strong,{children:"PointCloud2"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Topic: ",(0,r.jsx)(n.code,{children:"/visual_slam/tracking/slam_map"})]}),"\n",(0,r.jsx)(n.li,{children:"This displays the 3D map (sparse point cloud of features)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add"})," > ",(0,r.jsx)(n.strong,{children:"Path"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Topic: ",(0,r.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})]}),"\n",(0,r.jsx)(n.li,{children:"Shows robot trajectory (where it has traveled)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add"})," > ",(0,r.jsx)(n.strong,{children:"Image"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Topic: ",(0,r.jsx)(n.code,{children:"/front_stereo_camera/left/image_raw"})]}),"\n",(0,r.jsx)(n.li,{children:"Shows live camera feed"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Set ",(0,r.jsx)(n.strong,{children:"Fixed Frame"}),": ",(0,r.jsx)(n.code,{children:"map"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-3-observe-vslam-performance",children:"Step 3: Observe VSLAM Performance"}),"\n",(0,r.jsx)(n.p,{children:"As the robot moves, you should see:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Point cloud"})," growing (map being built)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Path"})," extending (robot trajectory)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TF frames"})," updating (robot pose changing)"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Healthy VSLAM Indicators"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Smooth trajectory (no sudden jumps)"}),"\n",(0,r.jsx)(n.li,{children:"Dense point cloud in explored areas"}),"\n",(0,r.jsx)(n.li,{children:"Consistent pose updates (30 Hz)"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-5-understanding-vslam-output",children:"Part 5: Understanding VSLAM Output"}),"\n",(0,r.jsx)(n.h3,{id:"key-ros-2-topics",children:"Key ROS 2 Topics"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Topic"}),(0,r.jsx)(n.th,{children:"Message Type"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"nav_msgs/Odometry"})}),(0,r.jsx)(n.td,{children:"Robot pose estimate (position + orientation)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/visual_slam/tracking/slam_map"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})}),(0,r.jsx)(n.td,{children:"3D map (feature landmarks)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/visual_slam/tracking/vo_pose"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"geometry_msgs/PoseStamped"})}),(0,r.jsx)(n.td,{children:"Visual odometry (without loop closure)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/visual_slam/status"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"isaac_ros_visual_slam_interfaces/VisualSlamStatus"})}),(0,r.jsx)(n.td,{children:"SLAM state (tracking/lost)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"inspecting-odometry",children:"Inspecting Odometry"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# View robot pose in real-time\nros2 topic echo /visual_slam/tracking/odometry\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Output Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"pose:\n  position:\n    x: 2.34\n    y: -1.56\n    z: 0.12\n  orientation:\n    x: 0.0\n    y: 0.0\n    z: 0.707\n    w: 0.707  # Facing 90\xb0 (heading east)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"inspecting-map-quality",children:"Inspecting Map Quality"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Count number of landmarks in map\nros2 topic echo /visual_slam/tracking/slam_map --field data | wc -l\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Good map"}),": 500+ landmarks for small room, 2000+ for warehouse"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-6-evaluating-slam-performance",children:"Part 6: Evaluating SLAM Performance"}),"\n",(0,r.jsx)(n.h3,{id:"metric-1-trajectory-accuracy-drift",children:"Metric 1: Trajectory Accuracy (Drift)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Test"}),": Drive robot in a square loop back to start position. Measure error."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom nav_msgs.msg import Odometry\nimport math\n\nclass DriftEvaluator:\n    def __init__(self):\n        self.start_pose = None\n        self.current_pose = None\n\n        self.subscription = node.create_subscription(\n            Odometry,\n            '/visual_slam/tracking/odometry',\n            self.pose_callback,\n            10\n        )\n\n    def pose_callback(self, msg):\n        if self.start_pose is None:\n            self.start_pose = msg.pose.pose\n        self.current_pose = msg.pose.pose\n\n    def calculate_drift(self):\n        dx = self.current_pose.position.x - self.start_pose.position.x\n        dy = self.current_pose.position.y - self.start_pose.position.y\n        drift = math.sqrt(dx**2 + dy**2)\n        return drift\n\n# After loop closure\nevaluator = DriftEvaluator()\n# ... drive loop ...\nprint(f\"Drift: {evaluator.calculate_drift():.3f} meters\")\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptable Drift"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"<5% of total distance traveled (e.g., <0.5m drift on 10m loop)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"metric-2-loop-closure-detection",children:"Metric 2: Loop Closure Detection"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Test"}),": Return to a previously visited location. VSLAM should recognize it and correct drift."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Check"})," ",(0,r.jsx)(n.code,{children:"/visual_slam/status"})," topic:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /visual_slam/status\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Look for ",(0,r.jsx)(n.code,{children:"loop_closure_count"})," field incrementing when revisiting areas."]}),"\n",(0,r.jsx)(n.h3,{id:"metric-3-tracking-loss",children:"Metric 3: Tracking Loss"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Test"}),": Cover camera or enter a textureless area (e.g., blank wall)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Check"})," ",(0,r.jsx)(n.code,{children:"/visual_slam/status"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"tracking_status: 2  # 0=TRACKING_LOST, 1=TRACKING_UNCERTAIN, 2=TRACKING_GOOD\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Good VSLAM"}),": Recovers quickly (<2 seconds) when returning to textured area."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-7-advanced-vslam-configuration",children:"Part 7: Advanced VSLAM Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"tuning-parameters",children:"Tuning Parameters"}),"\n",(0,r.jsx)(n.p,{children:"Edit Isaac ROS VSLAM configuration file:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"nano ~/ros2_ws/src/isaac_ros_visual_slam/config/visual_slam.yaml\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Parameters"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"visual_slam:\n  ros__parameters:\n    # Feature detection\n    num_features_per_frame: 1000  # More features = better but slower\n\n    # Tracking\n    min_num_features: 50  # Minimum to maintain tracking\n    max_feature_age: 25   # How long to track a feature\n\n    # Mapping\n    enable_loop_closure: true  # Detect revisited locations\n    loop_closure_frequency: 1.0  # Check every 1 second\n\n    # Performance\n    enable_imu_fusion: true  # Use IMU for better pose estimation\n    enable_gpu_acceleration: true  # Use CUDA\n"})}),"\n",(0,r.jsx)(n.h3,{id:"using-imu-fusion",children:"Using IMU Fusion"}),"\n",(0,r.jsx)(n.p,{children:"If your robot has an IMU (Carter does), enable fusion for better performance:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"enable_imu_fusion: true\nimu_topic: '/imu/data'\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Reduces drift during fast motions"}),"\n",(0,r.jsx)(n.li,{children:"Handles motion blur better"}),"\n",(0,r.jsx)(n.li,{children:"Improves loop closure detection"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-8-exporting-maps-for-navigation",children:"Part 8: Exporting Maps for Navigation"}),"\n",(0,r.jsx)(n.p,{children:"Once VSLAM builds a good map, save it for autonomous navigation."}),"\n",(0,r.jsx)(n.h3,{id:"step-1-save-map",children:"Step 1: Save Map"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Save point cloud map\nros2 service call /visual_slam/save_map isaac_ros_visual_slam_interfaces/srv/SaveMap \"{map_url: '/home/user/maps/warehouse_map.pcd'}\"\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-convert-to-occupancy-grid-for-nav2",children:"Step 2: Convert to Occupancy Grid (for Nav2)"}),"\n",(0,r.jsxs)(n.p,{children:["Isaac ROS VSLAM produces a ",(0,r.jsx)(n.strong,{children:"point cloud"})," (sparse 3D landmarks). Nav2 needs an ",(0,r.jsx)(n.strong,{children:"occupancy grid"})," (2D grid of free/occupied cells)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Conversion"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install octomap tools\nsudo apt install ros-humble-octomap-server\n\n# Convert point cloud to occupancy grid\nros2 run octomap_server octomap_saver_node -f /home/user/maps/warehouse_map.bt\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This creates a 2D occupancy grid ",(0,r.jsx)(n.code,{children:".pgm"})," file and ",(0,r.jsx)(n.code,{children:".yaml"})," metadata."]}),"\n",(0,r.jsx)(n.h3,{id:"step-3-use-map-with-nav2",children:"Step 3: Use Map with Nav2"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Launch Nav2 with saved map\nros2 launch nav2_bringup bringup_launch.py map:=/home/user/maps/warehouse_map.yaml\n"})}),"\n",(0,r.jsx)(n.p,{children:"Now the robot can navigate autonomously using the VSLAM-generated map!"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-9-common-vslam-issues--solutions",children:"Part 9: Common VSLAM Issues & Solutions"}),"\n",(0,r.jsx)(n.h3,{id:"issue-1-vslam-fails-to-initialize",children:"Issue 1: VSLAM Fails to Initialize"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptom"}),": No map points appear, tracking status = LOST"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Causes & Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Insufficient texture"}),": Environment too uniform (blank walls)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Add visual markers (posters, tape, objects with patterns)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Camera not moving"}),": VSLAM needs parallax to triangulate depth"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Move robot (or camera) to generate motion"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Camera calibration incorrect"}),": Wrong intrinsic parameters"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Re-calibrate camera using ROS 2 ",(0,r.jsx)(n.code,{children:"camera_calibration"})," package"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"issue-2-high-drift-map-warps-over-time",children:"Issue 2: High Drift (Map Warps Over Time)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptom"}),": Robot returns to start but map shows it 1-2 meters off"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Causes & Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"No loop closures"}),": Robot doesn't revisit areas"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Drive overlapping paths, ensure ",(0,r.jsx)(n.code,{children:"enable_loop_closure: true"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Poor feature quality"}),": Too few stable features"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Increase lighting, avoid reflective surfaces"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Fast motion"}),": Camera moves too quickly for feature tracking"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Reduce robot speed to <0.5 m/s during mapping"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"issue-3-tracking-lost-in-textureless-areas",children:"Issue 3: Tracking Lost in Textureless Areas"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptom"}),": Tracking status drops to LOST near blank walls or uniform floors"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Add ",(0,r.jsx)(n.strong,{children:"fiducial markers"})," (AprilTags) in sparse areas"]}),"\n",(0,r.jsxs)(n.li,{children:["Fuse with ",(0,r.jsx)(n.strong,{children:"wheel odometry"})," to maintain pose during tracking loss"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"enable_imu_fusion: true\nenable_wheel_odometry_fusion: true\nwheel_odom_topic: '/odom'\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"part-10-hands-on-exercise",children:"Part 10: Hands-On Exercise"}),"\n",(0,r.jsx)(n.h3,{id:"exercise-map-a-multi-room-environment",children:"Exercise: Map a Multi-Room Environment"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Objective"}),": Use VSLAM to create a complete map of a simulated office environment"]}),"\n",(0,r.jsx)(n.h4,{id:"requirements",children:"Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scene Setup"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Load: ",(0,r.jsx)(n.code,{children:"NVIDIA/Assets/Isaac/Environments/Office/office.usd"})," in Isaac Sim"]}),"\n",(0,r.jsx)(n.li,{children:"Add Carter robot at entrance"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"VSLAM Configuration"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Enable loop closure"}),"\n",(0,r.jsx)(n.li,{children:"Enable IMU fusion"}),"\n",(0,r.jsxs)(n.li,{children:["Set ",(0,r.jsx)(n.code,{children:"num_features_per_frame: 1200"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Mapping Task"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Drive robot through all rooms"}),"\n",(0,r.jsx)(n.li,{children:"Return to start location (trigger loop closure)"}),"\n",(0,r.jsx)(n.li,{children:"Map should cover 100+ square meters"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Validation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Drift at loop closure < 0.5 meters"}),"\n",(0,r.jsx)(n.li,{children:"Map has 3000+ landmarks"}),"\n",(0,r.jsx)(n.li,{children:"No tracking loss events (or recovers within 2 seconds)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"deliverables",children:"Deliverables"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Saved map file: ",(0,r.jsx)(n.code,{children:"office_vslam_map.pcd"})]}),"\n",(0,r.jsxs)(n.li,{children:["RViz screenshot showing:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Complete trajectory path"}),"\n",(0,r.jsx)(n.li,{children:"Point cloud map"}),"\n",(0,r.jsx)(n.li,{children:"Robot at final position"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Performance report:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Total distance traveled"}),"\n",(0,r.jsx)(n.li,{children:"Final drift error"}),"\n",(0,r.jsx)(n.li,{children:"Number of loop closures detected"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Estimated Time"}),": 1-2 hours"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"In this lesson, you learned:"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Visual SLAM principles (feature tracking, pose estimation, mapping)\n\u2705 Installing and configuring Isaac ROS VSLAM\n\u2705 Running VSLAM in Isaac Sim with simulated cameras\n\u2705 Visualizing maps and trajectories in RViz\n\u2705 Evaluating SLAM performance (drift, loop closure)\n\u2705 Exporting maps for autonomous navigation\n\u2705 Troubleshooting common VSLAM issues"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visual SLAM"})," enables map-free autonomous navigation using only cameras"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loop closure"})," is critical for correcting accumulated drift"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Texture-rich environments"})," perform best for visual SLAM"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," provides GPU-accelerated VSLAM optimized for NVIDIA hardware"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.p,{children:["In the next lesson (",(0,r.jsx)(n.strong,{children:"Object Detection"}),"), you'll learn:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Deep neural network inference for object detection"}),"\n",(0,r.jsx)(n.li,{children:"Running YOLO and Faster R-CNN in Isaac ROS"}),"\n",(0,r.jsx)(n.li,{children:"Real-time detection on camera streams"}),"\n",(0,r.jsx)(n.li,{children:"Integrating detection with robot actions (navigate to object, grasp, etc.)"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ORB-SLAM3 Paper"}),": ",(0,r.jsx)(n.a,{href:"https://arxiv.org/abs/2007.11898",children:"https://arxiv.org/abs/2007.11898"})," (state-of-the-art VSLAM algorithm)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS VSLAM Documentation"}),": ",(0,r.jsx)(n.a,{href:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_visual_slam/index.html",children:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_visual_slam/index.html"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RTAB-Map"}),": ",(0,r.jsx)(n.a,{href:"http://introlab.github.io/rtabmap/",children:"http://introlab.github.io/rtabmap/"})," (alternative VSLAM system)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visual SLAM Tutorial"}),": ",(0,r.jsx)(n.a,{href:"https://www.doc.ic.ac.uk/~ajd/Publications/cadena_etal_arxiv16.pdf",children:"https://www.doc.ic.ac.uk/~ajd/Publications/cadena_etal_arxiv16.pdf"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SLAM Benchmarking"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/MichaelGrupp/evo",children:"https://github.com/MichaelGrupp/evo"})," (evaluate trajectory accuracy)"]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{title:"Real-World Application",type:"tip",children:(0,r.jsx)(n.p,{children:"Tesla's Autopilot uses a form of visual SLAM (called \"Visual Odometry\") to track the car's position when GPS is unavailable (tunnels, parking garages). The same techniques work for humanoid robots!"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);